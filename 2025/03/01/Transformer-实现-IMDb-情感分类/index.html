<!DOCTYPE html>
<html lang="en">
<head>

    <!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no" />
<meta name="author" content="John Doe" />



<meta name="description" content="题目 在本次挑战中，你将使用IMDb电影评论数据集，该数据集包含50,000条影评，其中25,000条用于训练，25,000条用于测试。每条评论都被标记为正面或负面情感。 你的任务是使用Transformer模型，对该数据集进行情感分类。具体要求如下： 数据集下载：请下载IMDb数据集，确保数据集中包含train和test两个文件夹，分别用于训练和测试。 数据预处理：对文本数据进行必要的预处理，包">
<meta property="og:type" content="article">
<meta property="og:title" content="Transformer 实现 IMDb 情感分类">
<meta property="og:url" content="http://example.com/2025/03/01/Transformer-%E5%AE%9E%E7%8E%B0-IMDb-%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="题目 在本次挑战中，你将使用IMDb电影评论数据集，该数据集包含50,000条影评，其中25,000条用于训练，25,000条用于测试。每条评论都被标记为正面或负面情感。 你的任务是使用Transformer模型，对该数据集进行情感分类。具体要求如下： 数据集下载：请下载IMDb数据集，确保数据集中包含train和test两个文件夹，分别用于训练和测试。 数据预处理：对文本数据进行必要的预处理，包">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/img/transformer_imdb.png">
<meta property="article:published_time" content="2025-03-01T14:25:41.000Z">
<meta property="article:modified_time" content="2025-03-24T07:36:12.618Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="code">
<meta property="article:tag" content="Transformer">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/transformer_imdb.png">

<link rel="apple-touch-icon" href= "/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">



    <link rel="shortcut icon" href="/favicon.png">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">



<link rel="stylesheet" href="/css/style.css">




<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>Transformer 实现 IMDb 情感分类 | Hexo</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: false,
        isPost: true,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: 
    }
</script>


    <script> yiliaConfig.jquery_ui = [false]; </script>



    <script> yiliaConfig.rootUrl = "\/";</script>






<meta name="generator" content="Hexo 7.3.0"></head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/avatar.jpg" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/"></a></h1>
        </hgroup>

        

        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>Menu</li>
                        <li>Tags</li>
                        
                        <li>Friends</li>
                        
                        
                        <li>About Me</li>
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/about/">关于我</a></li>
                        
                            <li><a href="/categories/%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/">模型学习</a></li>
                        
                            <li><a href="/categories/%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF/">优化技术</a></li>
                        
                            <li><a href="/categories/project/">小试牛刀</a></li>
                        
                            <li><a href="/categories/%E7%94%9F%E6%B4%BB%E9%9A%8F%E8%AE%B0/">生活随记</a></li>
                        
                            <li><a href="/archives/">归档</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/ACGAN/" rel="tag">ACGAN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BERT/" rel="tag">BERT</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CycleGAN/" rel="tag">CycleGAN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DCGAN/" rel="tag">DCGAN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GAN/" rel="tag">GAN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Transformer/" rel="tag">Transformer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/WGAN/" rel="tag">WGAN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/WGAN-GP/" rel="tag">WGAN-GP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/code/" rel="tag">code</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A8%A1%E5%9E%8B/" rel="tag">模型</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" rel="tag">线性回归</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9A%8F%E8%AE%B0/" rel="tag">随记</a></li></ul>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://hexo.io">Hexo</a>
                    
                      <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://pages.github.com/">GitHub</a>
                    
                      <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="http://moxfive.xyz/">MOxFIVE</a>
                    
                    </div>
                </section>
                

                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">专注于前端</div>
                </section>
                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页"></a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/avatar.jpg" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页"></a></h1>
            </hgroup>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/about/">关于我</a></li>
                
                    <li><a href="/categories/%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/">模型学习</a></li>
                
                    <li><a href="/categories/%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF/">优化技术</a></li>
                
                    <li><a href="/categories/project/">小试牛刀</a></li>
                
                    <li><a href="/categories/%E7%94%9F%E6%B4%BB%E9%9A%8F%E8%AE%B0/">生活随记</a></li>
                
                    <li><a href="/archives/">归档</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="Tags" friends="Friends" about="About Me"/>
</nav>
      <div class="body-wrap"><article id="post-Transformer-实现-IMDb-情感分类" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2025/03/01/Transformer-%E5%AE%9E%E7%8E%B0-IMDb-%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/" class="article-date">
      <time datetime="2025-03-01T14:25:41.000Z" itemprop="datePublished">2025-03-01</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Transformer 实现 IMDb 情感分类
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/project/">project</a>
    </div>


        
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Transformer/" rel="tag">Transformer</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/code/" rel="tag">code</a></li></ul>
    </div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><ol>
<li>在本次挑战中，你将使用IMDb电影评论数据集，该数据集包含50,000条影评，其中25,000条用于训练，25,000条用于测试。每条评论都被标记为正面或负面情感。</li>
<li>你的任务是使用Transformer模型，对该数据集进行情感分类。具体要求如下：<ol>
<li>数据集下载：请下载IMDb数据集，确保数据集中包含train和test两个文件夹，分别用于训练和测试。</li>
<li>数据预处理：对文本数据进行必要的预处理，包括分词、去除停用词、填充等，以便用于Transformer模型的训练。</li>
<li>模型训练：利用Transformer模型对训练数据集进行训练，调整模型参数，使其在测试集上取得尽可能高的分类准确度。</li>
<li>模型评估：在训练过程中，及时监控模型在测试集上的性能，并记录模型在测试集上的分类准确率，将结果可视化（如损失函数，预测准确率等）。</li>
</ol>
</li>
</ol>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.optim.lr_scheduler <span class="keyword">import</span> OneCycleLR  <span class="comment"># type: ignore</span></span><br><span class="line"><span class="keyword">from</span> torchtext.datasets <span class="keyword">import</span> IMDB</span><br><span class="line"><span class="keyword">from</span> torchtext.data.utils <span class="keyword">import</span> get_tokenizer</span><br><span class="line"><span class="keyword">from</span> torchtext.vocab <span class="keyword">import</span> build_vocab_from_iterator</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, Dataset</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义文本分词器，使用 spaCy 进行英文分词</span></span><br><span class="line">tokenizer = get_tokenizer(<span class="string">&quot;spacy&quot;</span>, language=<span class="string">&quot;en_core_web_sm&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">collect_tokens</span>(<span class="params">data_iter</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param data_iter: IMDB数据集</span></span><br><span class="line"><span class="string">    :return: 返回单词列表</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    all_tokens = []</span><br><span class="line">    <span class="keyword">for</span> _, text <span class="keyword">in</span> data_iter:</span><br><span class="line">        tokens = tokenizer(text)</span><br><span class="line">        all_tokens.append(tokens)</span><br><span class="line">    <span class="keyword">return</span> all_tokens  <span class="comment"># 返回所有 tokens 的列表</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载 IMDB 数据集</span></span><br><span class="line">train_iter = IMDB(split=<span class="string">&quot;train&quot;</span>)</span><br><span class="line">test_iter = IMDB(split=<span class="string">&quot;test&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建词汇表</span></span><br><span class="line">vocab = build_vocab_from_iterator(collect_tokens(train_iter), max_tokens=<span class="number">20000</span>, specials=[<span class="string">&quot;&lt;pad&gt;&quot;</span>, <span class="string">&quot;&lt;unk&gt;&quot;</span>])</span><br><span class="line">vocab.set_default_index(vocab[<span class="string">&quot;&lt;unk&gt;&quot;</span>])  <span class="comment"># 设置未记录的词用 &lt;unk&gt; 代替</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">text_pipeline</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param text: 欲处理的文本列表</span></span><br><span class="line"><span class="string">    :return: 文本对应的索引列表</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    tokens = tokenizer(text)</span><br><span class="line">    max_length = <span class="number">100</span> <span class="comment"># 只需要前 100 长度</span></span><br><span class="line">    tokens = tokens[:max_length]</span><br><span class="line">    index = []</span><br><span class="line">    <span class="keyword">for</span> token <span class="keyword">in</span> tokens:</span><br><span class="line">        index.append(vocab[token])</span><br><span class="line">    <span class="keyword">return</span> index</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">label_pipeline</span>(<span class="params">label</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param label: 情感标签 pos 或 neg</span></span><br><span class="line"><span class="string">    :return:  将 pos 或 neg 映射为 1 或 0</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> <span class="keyword">if</span> label == <span class="string">&quot;pos&quot;</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">IMDBDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;自定义 IMDB 数据集类，用于加载 IMDB 电影评论数据&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data_iter</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        初始化</span></span><br><span class="line"><span class="string">        :param data_iter: 同时包含 （label，text） 的数据迭代器</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>.data = []</span><br><span class="line">        <span class="keyword">for</span> label, text <span class="keyword">in</span> data_iter:</span><br><span class="line">            <span class="variable language_">self</span>.data.append((text_pipeline(text), label_pipeline(label)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :return: 返回数据集 self.data 长度</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param idx: 索引</span></span><br><span class="line"><span class="string">        :return: 索引对应的单词</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.data[idx]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建训练集和测试集</span></span><br><span class="line">train_data = IMDBDataset(train_iter)</span><br><span class="line">test_data = IMDBDataset(test_iter)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">collate_fn</span>(<span class="params">batch</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    处理批量数据，对文本进行填充使其长度一致</span></span><br><span class="line"><span class="string">    :param batch: 批量数据</span></span><br><span class="line"><span class="string">    :return: 填充处理之后的结果</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    texts, labels = <span class="built_in">zip</span>(*batch)</span><br><span class="line"></span><br><span class="line">    lengths = []</span><br><span class="line">    <span class="keyword">for</span> text <span class="keyword">in</span> texts:</span><br><span class="line">        lengths.append(<span class="built_in">len</span>(text))</span><br><span class="line"></span><br><span class="line">    max_len = <span class="built_in">max</span>(lengths)</span><br><span class="line"></span><br><span class="line">    padded_texts = []</span><br><span class="line">    <span class="keyword">for</span> text <span class="keyword">in</span> texts:</span><br><span class="line">        padded_texts.append(text + [vocab[<span class="string">&quot;&lt;pad&gt;&quot;</span>]] * (max_len - <span class="built_in">len</span>(text)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> torch.tensor(padded_texts), torch.tensor(labels, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建数据加载器</span></span><br><span class="line">train_loader = DataLoader(train_data, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>, collate_fn=collate_fn)</span><br><span class="line">test_loader = DataLoader(test_data, batch_size=<span class="number">64</span>, shuffle=<span class="literal">False</span>, collate_fn=collate_fn)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PositionalEncoding</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; 定义位置编码类，为 Transformer 提供位置信息 &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, dropout</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param d_model: 词向量的维度</span></span><br><span class="line"><span class="string">        :param dropout: Dropout 的概率，用于防止过拟合。</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(p=dropout)</span><br><span class="line"></span><br><span class="line">        max_len = <span class="number">5000</span> <span class="comment"># 最大序列长度</span></span><br><span class="line">        position_code = torch.zeros(max_len, d_model) <span class="comment"># 储存位置编码</span></span><br><span class="line"></span><br><span class="line">        position_item = torch.arange(<span class="number">0</span>, max_len, dtype=torch.<span class="built_in">float</span>).unsqueeze(<span class="number">1</span>) <span class="comment"># 生成位置索引 形状是(max_len, 1)</span></span><br><span class="line"></span><br><span class="line">        div_term = torch.exp(torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>).<span class="built_in">float</span>() * (-np.log(<span class="number">10000.0</span>) / d_model))  <span class="comment"># 即 10000 ^ (-2i / d_model)</span></span><br><span class="line"></span><br><span class="line">        position_code[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position_item * div_term) <span class="comment"># 偶数位置</span></span><br><span class="line">        position_code[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position_item * div_term) <span class="comment"># 奇数位置</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.register_buffer(<span class="string">&#x27;position_code&#x27;</span>, position_code) <span class="comment"># 将位置编码矩阵注册为模型不参与训练的缓冲区</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        前向传播</span></span><br><span class="line"><span class="string">        :param x: 输入张量 (batch_size, seq_len, d_model)</span></span><br><span class="line"><span class="string">        :return:  添加位置编码之后的张量</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        x = x + <span class="variable language_">self</span>.position_code[:x.size(<span class="number">1</span>)] <span class="comment"># 只取前 seq_len 个位置编码</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.dropout(x)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TransformerClassifier</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; 定义 Transformer 分类模型 &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, embed_dim, num_heads, num_layers, hidden_dim, dropout</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        初始化</span></span><br><span class="line"><span class="string">        :param vocab_size: 词汇表的大小</span></span><br><span class="line"><span class="string">        :param embed_dim: 词嵌入的维度</span></span><br><span class="line"><span class="string">        :param num_heads: Multi-Head 的头数</span></span><br><span class="line"><span class="string">        :param num_layers: Encoder 的层数</span></span><br><span class="line"><span class="string">        :param hidden_dim: FNN的隐藏层维度</span></span><br><span class="line"><span class="string">        :param dropout: dropout 率</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.embedding = nn.Embedding(vocab_size, embed_dim) <span class="comment"># 进行词嵌入，完成离散的索引-&gt;可学习的向量</span></span><br><span class="line">        <span class="variable language_">self</span>.pos_encoder = PositionalEncoding(embed_dim, dropout) <span class="comment"># 完成位置信息的添加</span></span><br><span class="line"></span><br><span class="line">        encoder_layers = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=hidden_dim, dropout=dropout) <span class="comment"># 编码器层，传入若干所需的参数</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers) <span class="comment"># 完成若干个编码器层堆叠</span></span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(embed_dim, <span class="number">1</span>) <span class="comment"># 全连接层，完成分类</span></span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(dropout) <span class="comment"># Dropout 层</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, text</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        前向传播，完成计算流程</span></span><br><span class="line"><span class="string">        :param text: 输入的文本张量 形状为 (batch_size, seq_len)</span></span><br><span class="line"><span class="string">        :return:分类结果，形状为 (batch_size)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        embedded = <span class="variable language_">self</span>.embedding(text) <span class="comment"># 完成词嵌入映射，得到 (batch_size, seq_len, embed_dim)形状</span></span><br><span class="line">        embedded = <span class="variable language_">self</span>.dropout(embedded) <span class="comment"># dropout</span></span><br><span class="line"></span><br><span class="line">        embedded = <span class="variable language_">self</span>.pos_encoder(embedded) <span class="comment"># 添加位置编码</span></span><br><span class="line"></span><br><span class="line">        embedded = embedded.transpose(<span class="number">0</span>, <span class="number">1</span>) <span class="comment"># 调整张量的维度为 (seq_len, batch_size, embed_dim)</span></span><br><span class="line"></span><br><span class="line">        output = <span class="variable language_">self</span>.transformer_encoder(embedded) <span class="comment"># 通过 Transformer 编码器</span></span><br><span class="line">        output = output.mean(dim=<span class="number">0</span>) <span class="comment"># 对序列维度（seq_len）取均值，得到句子级别的表示， 形状变为 (batch_size, embed_dim)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.fc(output).squeeze(<span class="number">1</span>) <span class="comment"># 通过全连接层，得到分类结果，形状为 (batch_size, 1)，然后去除多余的维度，返回的形状为 (batch_size)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置模型参数</span></span><br><span class="line">embed_dim = <span class="number">512</span></span><br><span class="line">num_heads = <span class="number">4</span></span><br><span class="line">num_layers = <span class="number">4</span></span><br><span class="line">hidden_dim = <span class="number">512</span></span><br><span class="line">dropout = <span class="number">0.2</span></span><br><span class="line">epochs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化模型</span></span><br><span class="line">model = TransformerClassifier(</span><br><span class="line">    vocab_size=<span class="built_in">len</span>(vocab),</span><br><span class="line">    embed_dim=embed_dim,</span><br><span class="line">    num_heads=num_heads,</span><br><span class="line">    num_layers=num_layers,</span><br><span class="line">    hidden_dim=hidden_dim,</span><br><span class="line">    dropout=dropout</span><br><span class="line">).to(device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义优化器和损失函数</span></span><br><span class="line">optimizer = optim.AdamW(model.parameters(), lr=<span class="number">1e-4</span>, weight_decay=<span class="number">1e-2</span>)</span><br><span class="line">scheduler = OneCycleLR(</span><br><span class="line">    optimizer,</span><br><span class="line">    max_lr=<span class="number">1e-4</span>,         <span class="comment"># 训练中最高学习率</span></span><br><span class="line">    total_steps=epochs * <span class="built_in">len</span>(train_loader),  <span class="comment"># 总训练步数 = epoch数 * 每个epoch的batch数</span></span><br><span class="line">    pct_start=<span class="number">0.3</span>,       <span class="comment"># warmup 30% 训练步数</span></span><br><span class="line">    anneal_strategy=<span class="string">&#x27;cos&#x27;</span>,  <span class="comment"># 余弦退火策略</span></span><br><span class="line">    div_factor=<span class="number">10</span>,       <span class="comment"># 初始学习率 = max_lr / 10</span></span><br><span class="line">    final_div_factor=<span class="number">100</span> <span class="comment"># 结束学习率 = max_lr / 100</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">criterion = nn.BCEWithLogitsLoss().to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model, loader, optimizer, criterion, scheduler</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    epoch_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> text, label <span class="keyword">in</span> loader:</span><br><span class="line">        text, label = text.to(device), label.to(device)</span><br><span class="line">        predictions = model(text)</span><br><span class="line">        loss = criterion(predictions, label)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=<span class="number">1.0</span>)</span><br><span class="line">        optimizer.step()</span><br><span class="line">        scheduler.step()</span><br><span class="line"></span><br><span class="line">        epoch_loss += loss.item()</span><br><span class="line">    <span class="keyword">return</span> epoch_loss / <span class="built_in">len</span>(loader)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">model, loader, criterion</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    epoch_loss = <span class="number">0</span></span><br><span class="line">    correct, total = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> text, label <span class="keyword">in</span> loader:</span><br><span class="line">            text, label = text.to(device), label.to(device)</span><br><span class="line">            predictions = model(text)</span><br><span class="line"></span><br><span class="line">            loss = criterion(predictions, label)</span><br><span class="line">            epoch_loss += loss.item()</span><br><span class="line">            preds = torch.sigmoid(predictions) &gt; <span class="number">0.5</span></span><br><span class="line">            correct += (preds == label).<span class="built_in">sum</span>().item()</span><br><span class="line">            total += label.size(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> epoch_loss / <span class="built_in">len</span>(loader), correct / total</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练过程</span></span><br><span class="line">train_losses, test_losses, test_accs = [], [], []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    train_loss = train(model, train_loader, optimizer, criterion, scheduler)</span><br><span class="line">    test_loss, test_acc = evaluate(model, test_loader, criterion)</span><br><span class="line">    train_losses.append(train_loss)</span><br><span class="line">    test_losses.append(test_loss)</span><br><span class="line">    test_accs.append(test_acc)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Epoch: <span class="subst">&#123;epoch + <span class="number">1</span>:02&#125;</span>, Train Loss: <span class="subst">&#123;train_loss:<span class="number">.3</span>f&#125;</span>, Test Loss: <span class="subst">&#123;test_loss:<span class="number">.3</span>f&#125;</span>, Test Acc: <span class="subst">&#123;test_acc:<span class="number">.2</span>%&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存训练后的参数信息</span></span><br><span class="line">torch.save(model.state_dict(), <span class="string">&quot;model.pth&quot;</span>)</span><br><span class="line"><span class="comment"># 保存词汇表信息</span></span><br><span class="line">torch.save(vocab, <span class="string">&quot;vocab.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制模型训练和评估的可视化图表</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">5</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.plot(train_losses, label=<span class="string">&#x27;Train Loss&#x27;</span>)</span><br><span class="line">plt.plot(test_losses, label=<span class="string">&#x27;Test Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">&#x27;Loss Curve&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.plot(test_accs, label=<span class="string">&#x27;Test Accuracy&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">&#x27;Accuracy Curve&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p><img src="/img/transformer_imdb.png" alt="alt text"></p>

      
    </div>
    
  </div>
  
    
    <div class="copyright">
        <p><span>Title:</span><a href="/2025/03/01/Transformer-%E5%AE%9E%E7%8E%B0-IMDb-%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/">Transformer 实现 IMDb 情感分类</a></p>
        <p><span>Author:</span><a href="/" title="Back to Homepage"></a></p>
        <p><span>Created:</span>2025-03-01, 22:25:41</p>
        <p><span>Updated:</span>2025-03-24, 15:36:12</p>
        <p>
            <span>Full URL:</span><a class="post-url" href="/2025/03/01/Transformer-%E5%AE%9E%E7%8E%B0-IMDb-%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/" title="Transformer 实现 IMDb 情感分类">http://example.com/2025/03/01/Transformer-%E5%AE%9E%E7%8E%B0-IMDb-%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/</a>
            <span class="copy-path" data-clipboard-text="From http://example.com/2025/03/01/Transformer-%E5%AE%9E%E7%8E%B0-IMDb-%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/　　By " title="Copy Article&#39;s Link &amp; Author"><i class="fa fa-clipboard"></i></span>
            <script> var clipboard = new Clipboard('.copy-path'); </script>
        </p>
        <p>
            <span>License:</span><i class="fa fa-creative-commons"></i> <a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" title="CC BY-NC-SA 4.0 International" target = "_blank">"CC BY-NC-SA 4.0"</a> Keep Link &amp; Author if Distribute.
        </p>
    </div>



    <nav id="article-nav">
        
            <div id="article-nav-newer" class="article-nav-title">
                <a href="/2025/03/02/%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B/">
                    房价预测
                </a>
            </div>
        
        
            <div id="article-nav-older" class="article-nav-title">
                <a href="/2025/02/27/%E9%A2%84%E6%B5%8B%E7%B3%BB%E5%A4%96%E8%A1%8C%E6%98%9F%E8%BD%A8%E9%81%93%E5%91%A8%E6%9C%9F/">
                    预测系外行星轨道周期
                </a>
            </div>
        
    </nav>

  
</article>

    <div id="toc" class="toc-article">
        <strong class="toc-title">Contents</strong>
        
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%98%E7%9B%AE"><span class="toc-number">1.</span> <span class="toc-text">题目</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81"><span class="toc-number">2.</span> <span class="toc-text">代码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C"><span class="toc-number">3.</span> <span class="toc-text">结果</span></a></li></ol>
        
    </div>
    <style>
        .left-col .switch-btn,
        .left-col .switch-area {
            display: none;
        }
        .toc-level-3 i,
        .toc-level-3 ol {
            display: none !important;
        }
    </style>

    <input type="button" id="tocButton" value="Hide"  title="Show or Hide Table of Contents">

    <script>
        yiliaConfig.toc = ["Hide", "Show", !!"false"];
    </script>



    
<div class="share">
    
        <div class="bdsharebuttonbox">
            <a href="#" class="fa fa-twitter bds_twi" data-cmd="twi" title="分享到推特"></a>
            <a href="#" class="fa fa-weibo bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
            <a href="#" class="fa fa-qq bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a>
            <a href="#" class="fa fa-files-o bds_copy" data-cmd="copy" title="复制网址"></a>
            <a href="#" class="fa fa fa-envelope-o bds_mail" data-cmd="mail" title="通过邮件分享"></a>
            <a href="#" class="fa fa-weixin bds_weixin" data-cmd="weixin" title="生成文章二维码"></a>
            <a href="#" class="fa fa-share-alt bds_more" data-cmd="more"></i></a>
        </div>
        <script>
            window._bd_share_config={
                "common":{"bdSnsKey":{},"bdText":"Transformer 实现 IMDb 情感分类　| Hexo　","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
        </script>
    

    
</div>







    




    <div class="scroll" id="post-nav-button">
        
            <a href="/2025/03/02/%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B/" title="Pre: 房价预测">
                <i class="fa fa-angle-left"></i>
            </a>
        

        <a title="Mini Archives"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a>

        
            <a href="/2025/02/27/%E9%A2%84%E6%B5%8B%E7%B3%BB%E5%A4%96%E8%A1%8C%E6%98%9F%E8%BD%A8%E9%81%93%E5%91%A8%E6%9C%9F/" title="Next: 预测系外行星轨道周期">
                <i class="fa fa-angle-right"></i>
            </a>
        
    </div>

    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2025/03/24/%E9%93%BE%E6%97%B6%E4%BB%A3/">链时代招新</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/03/23/%E5%A4%9A%E7%94%9F%E6%88%90%E5%99%A8%E6%9E%B6%E6%9E%84/">多生成器架构</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/03/23/%E5%B1%82%E5%BD%92%E4%B8%80%E5%8C%96/">层归一化</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/03/23/Inception-Score/">Inception Score</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/03/23/hello-world/">Hello World</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/03/21/%E5%85%B3%E4%BA%8E-GAN-%E5%8F%8A%E5%85%B6%E8%A1%8D%E7%94%9F%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%AC%94%E8%AE%B0%E4%B8%8E%E6%80%9D%E8%80%83/">关于 GAN 及其衍生模型的笔记与思考</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/03/20/FID/">FID</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/03/20/%E5%85%B3%E4%BA%8E-Transformer-%E7%9A%84%E7%AC%94%E8%AE%B0%E4%B8%8E%E6%80%9D%E8%80%83/">关于 Transformer 的笔记与思考</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/03/18/CycleGAN-%E5%AE%9E%E7%8E%B0%E8%8E%AB%E5%A5%88%E9%A3%8E%E6%A0%BC%E7%94%BB%E4%BD%9C%E8%BD%AC%E5%8C%96%E4%B8%BA%E7%9C%9F%E5%AE%9E%E7%85%A7%E7%89%87/">CycleGAN 实现莫奈风格画作转化为真实照片</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/03/18/%E5%85%B3%E4%BA%8E-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-%E7%9A%84%E7%AC%94%E8%AE%B0%E4%B8%8E%E6%80%9D%E8%80%83/">关于 线性回归 的笔记与思考</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/03/13/WGAN-WGAN-GP-%E5%AE%9E%E7%8E%B0%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E7%94%9F%E6%88%90/">WGAN/WGAN-GP 实现手写数字生成</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/03/13/Wasserstein%E8%B7%9D%E7%A6%BB/">Wasserstein距离</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/03/13/KL%E6%95%A3%E5%BA%A6/">KL散度</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/03/12/ACGAN-%E5%AE%9E%E7%8E%B0%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E7%94%9F%E6%88%90/">ACGAN 实现手写数字生成</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/03/10/%E6%89%B9%E5%BD%92%E4%B8%80%E5%8C%96/">批归一化</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/03/09/DCGAN-%E5%AE%9E%E7%8E%B0%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E7%94%9F%E6%88%90/">DCGAN 实现手写数字生成</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/03/09/GAN-%E5%AE%9E%E7%8E%B0%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E7%94%9F%E6%88%90/">GAN 实现手写数字生成</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/03/06/BERT-%E5%AE%9E%E7%8E%B0-IMDb-%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/">BERT 实现 IMDb 情感分类</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/03/02/%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B/">房价预测</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/03/01/Transformer-%E5%AE%9E%E7%8E%B0-IMDb-%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/">Transformer 实现 IMDb 情感分类</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/02/27/%E9%A2%84%E6%B5%8B%E7%B3%BB%E5%A4%96%E8%A1%8C%E6%98%9F%E8%BD%A8%E9%81%93%E5%91%A8%E6%9C%9F/">预测系外行星轨道周期</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/02/23/%E6%B5%8B%E8%AF%95%E5%8D%9A%E5%AE%A2/">测试博客</a></li></ul>




    <script>
        
    </script>
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2025 John Doe
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank" title="A fast, simple &amp; powerful blog framework">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="Another simple and elegant theme for Hexo  v3.5">Yelee</a> by MOxFIVE <i class="fa fa-heart animated infinite pulse"></i>
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" title="Site Visitors"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit"  title="Page Hits"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>
    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = 5;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>





<div class="scroll" id="scroll">
    <a href="#" title="Back to Top"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="Comments"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="Go to Bottom"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
            
            
            
            
            
            
             archives: ".archive-article-title", 
             miniArchives: "a.post-list-link", 
            
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>