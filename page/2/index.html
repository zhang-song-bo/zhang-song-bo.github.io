<!DOCTYPE html>
<html lang="en">
<head>

    <!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no" />
<meta name="author" content="John Doe" />


    
    


<meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">

<link rel="apple-touch-icon" href= "/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">



    <link rel="shortcut icon" href="/favicon.png">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">



<link rel="stylesheet" href="/css/style.css">



    <style> .article { opacity: 0;} </style>


<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>Hexo</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: true,
        isPost: false,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: 
    }
</script>


    <script> yiliaConfig.jquery_ui = [false]; </script>



    <script> yiliaConfig.rootUrl = "\/";</script>






<meta name="generator" content="Hexo 7.3.0"></head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/avatar.jpg" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/"></a></h1>
        </hgroup>

        

        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>Menu</li>
                        <li>Tags</li>
                        
                        <li>Friends</li>
                        
                        
                        <li>About Me</li>
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/about/">关于我</a></li>
                        
                            <li><a href="/categories/%E7%94%9F%E6%B4%BB%E9%9A%8F%E8%AE%B0/">生活随记</a></li>
                        
                            <li><a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a></li>
                        
                            <li><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li>
                        
                            <li><a href="/categories/%E7%AE%97%E6%B3%95/">算法</a></li>
                        
                            <li><a href="/archives/">所有文章</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/ACGAN/" rel="tag">ACGAN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BERT/" rel="tag">BERT</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CycleGAN/" rel="tag">CycleGAN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DCGAN/" rel="tag">DCGAN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GAN/" rel="tag">GAN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LLM/" rel="tag">LLM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LLM-Evaluation/" rel="tag">LLM Evaluation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LoRA/" rel="tag">LoRA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Multi-Agent/" rel="tag">Multi-Agent</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/" rel="tag">NLP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Prompt-Engineering/" rel="tag">Prompt Engineering</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SVM/" rel="tag">SVM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TF-IDF/" rel="tag">TF-IDF</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Transformer/" rel="tag">Transformer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/WGAN/" rel="tag">WGAN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/WGAN-GP/" rel="tag">WGAN-GP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/agent/" rel="tag">agent</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/code/" rel="tag">code</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/multi-agent/" rel="tag">multi-agent</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF/" rel="tag">优化技术</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E5%8F%96/" rel="tag">关键词提取</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%85%B7%E8%BA%AB%E6%99%BA%E8%83%BD/" rel="tag">具身智能</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/" rel="tag">分类模型</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/" rel="tag">分类算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/" rel="tag">图像风格迁移</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AF%B9%E9%BD%90/" rel="tag">对齐</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" rel="tag">强化学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BE%AE%E8%B0%83/" rel="tag">微调</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/" rel="tag">推理优化</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/" rel="tag">支持向量机</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90/" rel="tag">文本分析</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A8%A1%E5%9E%8B/" rel="tag">模型</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A8%A1%E6%8B%9F%E4%BA%BA%E7%B1%BB%E8%A1%8C%E4%B8%BA/" rel="tag">模拟人类行为</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" rel="tag">线性回归</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/" rel="tag">逻辑回归</a></li></ul>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://hexo.io">Hexo</a>
                    
                      <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://pages.github.com/">GitHub</a>
                    
                      <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="http://moxfive.xyz/">MOxFIVE</a>
                    
                    </div>
                </section>
                

                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">专注于前端</div>
                </section>
                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页"></a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/avatar.jpg" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页"></a></h1>
            </hgroup>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/about/">关于我</a></li>
                
                    <li><a href="/categories/%E7%94%9F%E6%B4%BB%E9%9A%8F%E8%AE%B0/">生活随记</a></li>
                
                    <li><a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a></li>
                
                    <li><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li>
                
                    <li><a href="/categories/%E7%AE%97%E6%B3%95/">算法</a></li>
                
                    <li><a href="/archives/">所有文章</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="Tags" friends="Friends" about="About Me"/>
</nav>
      <div class="body-wrap">
  
    <article id="post-二分" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2025/05/30/%E4%BA%8C%E5%88%86/" class="article-date">
      <time datetime="2025-05-30T12:04:33.000Z" itemprop="datePublished">2025-05-30</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/05/30/%E4%BA%8C%E5%88%86/">二分</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="二分"><a href="#二分" class="headerlink" title="二分"></a>二分</h1><p>思想很容易理解，但是写起来可能就会出现很多问题，下面给出一套完整的模板：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> n;</span><br><span class="line">vector&lt;<span class="type">int</span>&gt; nums;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 自定义 upper_bound，返回 &lt;= target 的最大下标</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">my_upper_bound</span><span class="params">(<span class="type">int</span> target)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> l = <span class="number">-1</span>;</span><br><span class="line">    <span class="type">int</span> r = n;</span><br><span class="line">    <span class="keyword">while</span> (l + <span class="number">1</span> != r) &#123;</span><br><span class="line">        <span class="type">int</span> mid = (l + r) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span> (nums[mid] &lt;= target) &#123;</span><br><span class="line">            l = mid;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            r = mid;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> l;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 自定义 lower_bound，返回 &gt;= target 的最小下标</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">my_lower_bound</span><span class="params">(<span class="type">int</span> target)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> l = <span class="number">-1</span>;</span><br><span class="line">    <span class="type">int</span> r = n;</span><br><span class="line">    <span class="keyword">while</span> (l + <span class="number">1</span> != r) &#123;</span><br><span class="line">        <span class="type">int</span> mid = (l + r) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span> (nums[mid] &gt;= target) &#123;</span><br><span class="line">            r = mid;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            l = mid;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> r;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 初始化有序数组</span></span><br><span class="line">    nums = &#123;<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">15</span>&#125;;</span><br><span class="line">    n = nums.<span class="built_in">size</span>();</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> target = <span class="number">9</span>;</span><br><span class="line">    <span class="type">int</span> lo = <span class="built_in">my_lower_bound</span>(target);</span><br><span class="line">    <span class="type">int</span> up = <span class="built_in">my_upper_bound</span>(target);</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;Target: &quot;</span> &lt;&lt; target &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;Lower bound index: &quot;</span> &lt;&lt; lo &lt;&lt; <span class="string">&quot;, Value: &quot;</span> &lt;&lt; (lo &lt; n ? nums[lo] : <span class="number">-1</span>) &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;Upper bound index: &quot;</span> &lt;&lt; up &lt;&lt; <span class="string">&quot;, Value: &quot;</span> &lt;&lt; (up &gt;= <span class="number">0</span> ? nums[up] : <span class="number">-1</span>) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/%E7%AE%97%E6%B3%95/">算法</a>
    </div>


      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-欧拉质数筛" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2025/05/30/%E6%AC%A7%E6%8B%89%E8%B4%A8%E6%95%B0%E7%AD%9B/" class="article-date">
      <time datetime="2025-05-30T12:04:20.000Z" itemprop="datePublished">2025-05-30</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/05/30/%E6%AC%A7%E6%8B%89%E8%B4%A8%E6%95%B0%E7%AD%9B/">欧拉质数筛</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="欧拉质数筛"><a href="#欧拉质数筛" class="headerlink" title="欧拉质数筛"></a>欧拉质数筛</h1><p>欧拉质数筛是一种时间复杂度为O(n)快速找出1~n之间的质数的算法</p>
<p><strong>核心思想是：每个合数制备他的最小质因子筛一次，从而保证时间复杂度为O(n)</strong></p>
<p>详细算法：</p>
<ol>
<li><p>从小到大枚举每个整数 <code>i</code>，如果 <code>is_prime[i] == true</code>，说明它是一个质数，加入质数表。</p>
</li>
<li><p>用所有已知的质数 <code>p</code> 去筛掉 <code>i * p</code>：标记 <code>i * p</code> 为合数（<code>is_prime[i * p] = false</code>）。</p>
</li>
<li><p>一旦 <code>p</code> 是 <code>i</code> 的最小质因子（即 <code>i % p == 0</code>），就<strong>停止筛这个 <code>i</code> 后面的合数</strong>：因为 <code>i * p1</code>（p1 &gt; p）在后面一定会由更小的因子组合构造出来，重复了。</p>
</li>
</ol>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> n = <span class="number">10000</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">bool</span> is_prime[<span class="number">10000</span> + <span class="number">4</span>];</span><br><span class="line">vector&lt;<span class="type">int</span>&gt; primes;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">euler_prime</span><span class="params">(<span class="type">int</span> n)</span></span>&#123;</span><br><span class="line">    <span class="built_in">fill</span>(is_prime, is_prime + n + <span class="number">1</span>, <span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">	is_prime[<span class="number">0</span>] = is_prime[<span class="number">1</span>] = <span class="literal">false</span>;</span><br><span class="line">	<span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">2</span>; i &lt;= n; i ++)&#123;</span><br><span class="line">		<span class="keyword">if</span>(is_prime[i] == <span class="literal">true</span>)</span><br><span class="line">			primes.<span class="built_in">push_back</span>(i);</span><br><span class="line">		<span class="keyword">for</span>(<span class="type">int</span> p : primes)&#123;</span><br><span class="line">			<span class="keyword">if</span>(i * p &gt; n)</span><br><span class="line">				<span class="keyword">break</span>;</span><br><span class="line">			is_prime[i * p] = <span class="literal">false</span>;</span><br><span class="line">			<span class="keyword">if</span>(i % p == <span class="number">0</span>)</span><br><span class="line">				<span class="keyword">break</span>;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="built_in">euler_prime</span>(n);</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; primes.<span class="built_in">size</span>(); ++i)</span><br><span class="line">    	cout &lt;&lt; primes[i] &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">euler_sieve</span>(<span class="params">n</span>):</span><br><span class="line">    is_prime = [<span class="literal">True</span>] * (n + <span class="number">1</span>)</span><br><span class="line">    is_prime[<span class="number">0</span>] = is_prime[<span class="number">1</span>] = <span class="literal">False</span></span><br><span class="line">    primes = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, n + <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">if</span> is_prime[i]:</span><br><span class="line">            primes.append(i)</span><br><span class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> primes:</span><br><span class="line">            <span class="keyword">if</span> i * p &gt; n:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            is_prime[i * p] = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">if</span> i % p == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> primes</span><br><span class="line"></span><br><span class="line">n = <span class="number">10000</span></span><br><span class="line">primes = euler_sieve(n)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; &quot;</span>.join(<span class="built_in">map</span>(<span class="built_in">str</span>, primes)))</span><br></pre></td></tr></table></figure>


      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/%E7%AE%97%E6%B3%95/">算法</a>
    </div>


      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Towards-Efficient-and-Scalable-Multi-agent-Reasoning-via-Bayesian-Nash-Equilibrium" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2025/05/28/Towards-Efficient-and-Scalable-Multi-agent-Reasoning-via-Bayesian-Nash-Equilibrium/" class="article-date">
      <time datetime="2025-05-28T13:54:07.000Z" itemprop="datePublished">2025-05-28</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/05/28/Towards-Efficient-and-Scalable-Multi-agent-Reasoning-via-Bayesian-Nash-Equilibrium/">Towards Efficient and Scalable Multi-agent Reasoning via Bayesian Nash Equilibrium</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>《Towards Efficient and Scalable Multi-agent Reasoning via Bayesian Nash Equilibrium核心思想是利用**贝叶斯纳什均衡（Bayesian Nash Equilibrium, BNE）**来解决多智能体（Multi-agent）推理中的效率和可扩展性问题，特别是针对大型语言模型（LLMs）构成的多智能体系统。</p>
<p>由于对贝叶斯纳什均衡不是很了解，先从基础概念开始，然后逐步深入到论文的应用。</p>
<h3 id="1-什么是纳什均衡-Nash-Equilibrium-？"><a href="#1-什么是纳什均衡-Nash-Equilibrium-？" class="headerlink" title="1. 什么是纳什均衡 (Nash Equilibrium)？"></a>1. 什么是纳什均衡 (Nash Equilibrium)？</h3><p>在理解贝叶斯纳什均衡之前，我们需要先了解普通的纳什均衡。纳什均衡是博弈论中的一个核心概念，它描述了这样一种状态：在一个多方参与的博弈中，<strong>每个参与者都选择了自己的最优策略，并且假设其他参与者也选择了他们的最优策略，在这种情况下，没有任何一个参与者可以通过单方面改变自己的策略来获得更好的结果。</strong></p>
<p><strong>举个例子：囚徒困境</strong></p>
<p>假设有两个嫌疑犯，A和B，因涉嫌犯罪被捕。警方分别审问他们，并提供以下条件：</p>
<ul>
<li>如果A和B都保持沉默，他们都只判1年监禁。</li>
<li>如果A背叛B（告发B），B保持沉默，A无罪释放，B判10年监禁。</li>
<li>如果B背叛A，A保持沉默，B无罪释放，A判10年监禁。</li>
<li>如果A和B都背叛对方，他们都判5年监禁。</li>
</ul>
<p>我们用一个表格来表示他们的收益（负数表示监禁年数）：</p>
<table>
<thead>
<tr>
<th></th>
<th><strong>B 保持沉默</strong></th>
<th><strong>B 背叛</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>A 保持沉默</strong></td>
<td>(-1, -1)</td>
<td>(-10, 0)</td>
</tr>
<tr>
<td><strong>A 背叛</strong></td>
<td>(0, -10)</td>
<td>(-5, -5)</td>
</tr>
</tbody></table>
<p>（括号内第一个数字是A的收益，第二个是B的收益）</p>
<p>现在，我们来分析纳什均衡：</p>
<ul>
<li>对A而言：<ul>
<li>如果B保持沉默，A选择“背叛”会更好（从-1变成0）。</li>
<li>如果B背叛，A选择“背叛”也会更好（从-10变成-5）。</li>
<li>所以，无论B做什么，A的最佳策略都是“背叛”。</li>
</ul>
</li>
<li>对B而言：<ul>
<li>如果A保持沉默，B选择“背叛”会更好（从-1变成0）。</li>
<li>如果A背叛，B选择“背叛”也会更好（从-10变成-5）。</li>
<li>所以，无论A做什么，B的最佳策略都是“背叛”。</li>
</ul>
</li>
</ul>
<p>结果是，A和B最终都会选择“背叛”，并且他们都将被判5年监禁。在这个“都背叛”的状态下，任何一方单方面改变策略（例如A从“背叛”改为“保持沉默”）都不会让自己的情况变好（A会从-5变成-10）。因此，<strong>(背叛, 背叛)</strong> 就是这个博弈的纳什均衡。</p>
<h3 id="2-什么是贝叶斯纳什均衡-Bayesian-Nash-Equilibrium-BNE-？"><a href="#2-什么是贝叶斯纳什均衡-Bayesian-Nash-Equilibrium-BNE-？" class="headerlink" title="2. 什么是贝叶斯纳什均衡 (Bayesian Nash Equilibrium, BNE)？"></a>2. 什么是贝叶斯纳什均衡 (Bayesian Nash Equilibrium, BNE)？</h3><p>普通的纳什均衡假设所有参与者都<strong>完全知道</strong>博弈的规则、其他玩家的策略以及他们的偏好（收益）。但在现实世界中，这种情况很少见。很多时候，玩家对其他玩家的“类型”（比如他们的能力、信息、偏好等）存在<strong>不确定性</strong>。</p>
<p>**贝叶斯纳什均衡就是在这种“信息不完全”的博弈中应用的纳什均衡概念。**它考虑了玩家的“信念”（beliefs）——即玩家对其他玩家类型的概率分布的判断。在贝叶斯纳什均衡中，每个玩家选择一个策略，使得在给定自己所知道的信息（自己的类型）以及对其他玩家类型的“信念”下，自己的**期望收益**最大化，并且这个策略是针对其他玩家的最优策略的。</p>
<p><strong>核心思想：</strong></p>
<ul>
<li><strong>不完全信息：</strong> 玩家不完全知道其他玩家的“类型”（比如，他们是高效率的还是低效率的，是激进的还是保守的）。</li>
<li><strong>类型（Type）：</strong> 每个玩家都有一个“类型”，这个类型包含了玩家的私有信息（比如成本、能力、偏好等）。这个类型是玩家自己知道，但其他玩家不完全知道的。</li>
<li><strong>信念（Beliefs）：</strong> 玩家会根据他们所知道的信息，对其他玩家的类型形成一个概率分布的“信念”。例如，玩家A可能认为玩家B是“激进型”的概率是0.7，是“保守型”的概率是0.3。</li>
<li><strong>期望收益（Expected Payoff）：</strong> 由于存在不确定性，玩家不能直接知道其他玩家会做什么，所以他们会根据自己的“信念”来计算选择某个策略可能带来的平均收益，即期望收益。</li>
<li><strong>最优策略：</strong> 在贝叶斯纳什均衡中，每个玩家选择的策略是：在给定自己类型和对其他玩家类型信念的情况下，使其<strong>期望收益最大化</strong>的策略。同时，这些策略是相互最佳回应的。</li>
</ul>
<p><strong>举个例子：拍卖会（第一价格密封竞价拍卖）</strong></p>
<p>假设有一个艺术品拍卖会，有两位竞拍者A和B。他们各自对艺术品有一个<strong>私人估价</strong>（valuation），这个估价只有他们自己知道。</p>
<ul>
<li>A的估价vA可以是高（H）或低（L）。</li>
<li>B的估价vB可以是高（H）或低（L）。</li>
<li>假设双方都知道，对方估价为H的概率是p，估价为L的概率是1−p。</li>
<li>出价最高者赢得艺术品，并支付自己的出价。如果出价相同，则随机决定。</li>
<li>收益 &#x3D; 艺术品估价 - 支付价格（如果赢了），否则为0。</li>
</ul>
<p>在这个例子中：</p>
<ul>
<li><strong>玩家：</strong> A和B。</li>
<li><strong>行动：</strong> 出价（任何非负实数）。</li>
<li><strong>类型：</strong> 玩家的私人估价（高估价或低估价）。这是私人信息。</li>
<li><strong>信念：</strong> 玩家对对方估价的概率分布（例如，A相信B是高估价的概率是p）。</li>
<li><strong>贝叶斯纳什均衡：</strong> 双方会根据自己的估价类型，以及对对方估价的信念，选择一个最优的出价策略，使得自己的期望收益最大化。</li>
</ul>
<p>例如，一个简化的贝叶斯纳什均衡策略可能是：</p>
<ul>
<li>如果你的估价是高（H），你出价XH。</li>
<li>如果你的估价是低（L），你出价XL。</li>
</ul>
<p>并且，XH和XL是各自估价类型下的最佳出价，考虑到对方也可能采取类似的策略（根据其估价类型选择出价）。</p>
<p>在第一价格密封竞价拍卖中，常见的贝叶斯纳什均衡策略是**“压低出价”**：每个竞拍者会出价低于自己的真实估价，以在赢得拍卖的同时保留一部分收益。具体压低多少取决于他们对其他竞拍者估价分布的信念。</p>
<h3 id="3-《Towards-Efficient-and-Scalable-Multi-agent-Reasoning-via-Bayesian-Nash-Equilibrium》论文解读"><a href="#3-《Towards-Efficient-and-Scalable-Multi-agent-Reasoning-via-Bayesian-Nash-Equilibrium》论文解读" class="headerlink" title="3. 《Towards Efficient and Scalable Multi-agent Reasoning via Bayesian Nash Equilibrium》论文解读"></a>3. 《Towards Efficient and Scalable Multi-agent Reasoning via Bayesian Nash Equilibrium》论文解读</h3><p>这篇论文旨在解决多智能体推理系统（特别是基于LLM的系统）中存在的<strong>高计算成本</strong>和<strong>缺乏理论收敛性保证</strong>的问题。传统的LLM多智能体系统（例如，通过多轮辩论来达成共识）虽然能提高答案准确性，但其交互成本巨大，且不总是能保证最终收敛到最优解。</p>
<p>论文提出了一个名为 <strong>EcoNash (Efficient Coordination via Nash Equilibrium)</strong> 的新框架，它将贝叶斯纳什均衡的概念引入到多LLM系统中，以实现高效和可扩展的多智能体推理。</p>
<p><strong>论文的核心观点和方法：</strong></p>
<ol>
<li><strong>将多LLM推理建模为具有不完全信息的博弈：</strong><ul>
<li>在多LLM系统中，每个LLM可以被视为一个“智能体”。</li>
<li>每个LLM可能拥有“私有信息”或“私有能力”，例如它所“知道”的知识（基于其训练数据和检索到的信息）、它的推理能力、它对某个特定问题的理解侧重等。这些是其他LLM不完全知道的。</li>
<li>因此，当一个LLM需要与其他LLM协作解决问题时，它对其他LLM的“类型”（即其内部信息和能力）存在不确定性。这正好符合贝叶斯博弈的设定。</li>
<li>论文认为，通过让LLM在不完全信息下达成贝叶斯纳什均衡，可以减少它们之间的通信量，从而提高效率。</li>
</ul>
</li>
<li><strong>EcoNash 框架：</strong><ul>
<li>EcoNash 框架采用<strong>分层强化学习</strong>的结构，包含一个**中央LLM（Coordinator&#x2F;Central LLM）**和多个**执行LLM（Execution LLMs）**。</li>
<li><strong>中央LLM（协调者）：</strong> 负责提供高层次的策略、指导和格式要求。它就像一个“项目经理”，设定方向和规则。</li>
<li><strong>执行LLMs：</strong> 独立地根据中央LLM的指导和自身所掌握的“信念”（私有信息），生成答案或推理步骤。它们就像“具体执行者”，根据自己的理解去完成任务。</li>
<li>贝叶斯纳什均衡的应用：<ul>
<li>每个执行LLM在生成答案时，会考虑它对其他执行LLM可能“知道”什么或可能如何行动的<strong>信念</strong>。</li>
<li>中央LLM在设计指导策略时，也会考虑执行LLM的各种“类型”可能性，并试图找到一个能让所有执行LLM（根据它们的类型和信念）都能最优地做出回应的策略。</li>
<li>这种设计使得每个执行LLM可以在<strong>不进行大量实时沟通</strong>的情况下，独立地生成“最优”响应，因为它们对其他智能体行为的预期已经通过贝叶斯信念融入了它们的决策过程。</li>
<li>最终，中央LLM会整合所有执行LLM的答案，形成最终的“承诺”（commitment）。</li>
</ul>
</li>
</ul>
</li>
<li><strong>效率和可扩展性：</strong><ul>
<li>通过贝叶斯纳什均衡，LLM之间<strong>不需要进行高成本的实时交互和多轮辩论</strong>来达成共识。每个LLM基于其自身的信念和对其他LLM的预期来独立决策，大大减少了通信和计算开销。</li>
<li>这种设计使得系统更容易扩展到更多的LLM智能体，因为智能体之间不再需要密集地互相通信。</li>
<li>论文还提供了一些理论分析，证明了EcoNash在性能改进上具有较好的理论界限，并且其后悔（regret）增长与时间T呈亚线性关系，优于其他未达到BNE的多智能体框架。</li>
</ul>
</li>
</ol>
<p><strong>结合实例理解：一个多LLM的法律咨询系统</strong></p>
<p>假设我们有一个由多个LLM组成的法律咨询系统，用户输入一个复杂的法律问题，需要系统给出详细的法律建议。</p>
<ul>
<li><p><strong>传统多智能体辩论方法（非BNE）：</strong></p>
<ul>
<li>用户输入问题。</li>
<li>LLM1生成一个初步回答。</li>
<li>LLM2对LLM1的回答进行批评和补充。</li>
<li>LLM3再对LLM2的批评进行反驳或整合。</li>
<li>这个过程可能持续多轮，直到所有LLM达成一个共识。</li>
<li><strong>问题：</strong> 每轮都需要LLM之间进行大量信息交换和推理，耗时且计算资源消耗大。如果某个LLM“固执己见”，可能导致长时间的僵持或无法收敛。</li>
</ul>
</li>
<li><p><strong>EcoNash 框架（基于BNE）：</strong></p>
<ul>
<li><p><strong>中央LLM（协调者）：</strong> 接收用户的法律问题。它首先对问题进行分解，并提供一个“框架”或“思考路径”。例如，它可能指示：“请各位执行LLM分别从以下几个方面分析：1. 相关法律条文；2. 历史判例；3. 潜在风险；4. 建议方案。每部分请提供两段概括性文字。”</p>
</li>
<li><p>执行LLMs：</p>
<p> 假设有LLM_A（擅长刑法）、LLM_B（擅长民法）、LLM_C（擅长合同法）。</p>
<ul>
<li>中央LLM将框架发给它们。</li>
<li>LLM_A知道自己擅长刑法，并且它“相信”（或者系统设定让它相信）LLM_B更擅长民法，LLM_C更擅长合同法。</li>
<li>LLM_A在分析“相关法律条文”时，会根据自己的刑法知识进行深入检索和推理。它同时会预期到LLM_B和LLM_C也会在各自擅长的领域提供有价值的信息。它不需要和LLM_B、LLM_C实时“讨论”哪些法律条文更重要，而是基于对它们“类型”的信念，自行判断自己的最优贡献。</li>
<li>每个执行LLM独立地生成其指定部分的答案，并按照中央LLM要求的格式返回。</li>
</ul>
</li>
<li><p><strong>中央LLM（整合者）：</strong> 接收所有执行LLM独立生成的答案。它会根据预设的整合机制（例如，投票、加权平均、或进一步的总结）将这些答案整合起来，形成最终的、全面的法律咨询报告。</p>
</li>
<li><p>优点：</p>
<ul>
<li><strong>效率高：</strong> LLM之间无需频繁交互，降低了通信开销。每个LLM可以并行工作。</li>
<li><strong>可扩展性强：</strong> 很容易增加或减少执行LLM的数量，因为它们之间的依赖性较低，主要通过中央LLM进行协调。</li>
<li><strong>理论保证：</strong> 论文通过贝叶斯纳什均衡的理论，为这种分布式推理提供了更强的收敛性和性能保证，避免了传统辩论系统可能出现的僵局。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h3><p>《Towards Efficient and Scalable Multi-agent Reasoning via Bayesian Nash Equilibrium》这篇论文的核心在于，它认识到多智能体系统中的“信息不完全”是常态，并创造性地引入了贝叶斯纳什均衡来解决这个问题。通过构建一个分层结构（中央LLM负责协调，执行LLM独立推理），并让智能体基于对其他智能体“类型”的信念来优化自己的期望收益，该框架显著提高了多LLM推理的效率和可扩展性，同时提供了更强的理论收敛性保障。这对于构建更强大、更实用的基于LLM的智能系统具有重要意义。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LLM/" rel="tag">LLM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/multi-agent/" rel="tag">multi-agent</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/" rel="tag">推理优化</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-LoRA" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2025/05/28/LoRA/" class="article-date">
      <time datetime="2025-05-28T13:44:04.000Z" itemprop="datePublished">2025-05-28</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/05/28/LoRA/">LoRA</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <hr>
<h1 id="LoRA-Low-Rank-Adaptation-of-Large-Language-Models"><a href="#LoRA-Low-Rank-Adaptation-of-Large-Language-Models" class="headerlink" title="LoRA: Low-Rank Adaptation of Large Language Models"></a>LoRA: Low-Rank Adaptation of Large Language Models</h1><p>原论文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2106.09685">arXiv:2106.09685</a><br> 项目主页：<a target="_blank" rel="noopener" href="https://github.com/microsoft/LoRA">GitHub - microsoft&#x2F;LoRA</a></p>
<h2 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h2><p>随着大型语言模型（LLMs）如 GPT-3 的广泛应用，如何高效地将其适配到特定任务成为了一个关键问题。传统的微调方法需要更新模型中<strong>所有的参数</strong>，这在计算资源和存储方面都带来了巨大的挑战。为了解决这一问题，微软研究院提出了 LoRA（Low-Rank Adaptation）方法，旨在以更低的计算成本实现对大型模型的高效微调。</p>
<h2 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h2><p>LoRA 的核心理念是：<strong>在微调过程中，模型参数的更新可以被近似为一个低秩矩阵的形式</strong>。具体而言，LoRA 冻结预训练模型的原始权重，仅在每一层中引入可训练的低秩矩阵，从而大幅减少需要更新的参数数量。</p>
<p>通过这种方式，LoRA 实现了以下目标：</p>
<ul>
<li><strong>参数高效</strong>：相比全量微调，LoRA 将可训练参数数量减少了约 10,000 倍。</li>
<li><strong>内存节省</strong>：GPU 内存需求降低了约 3 倍。</li>
<li><strong>性能保持</strong>：在多个任务上，LoRA 的性能与全量微调相当，甚至更优。</li>
</ul>
<h2 id="方法流程详解"><a href="#方法流程详解" class="headerlink" title="方法流程详解"></a>方法流程详解</h2><p>LoRA 的实现过程如下：</p>
<ol>
<li><strong>冻结原始权重</strong>：预训练模型的原始权重保持不变。</li>
<li><strong>引入低秩矩阵</strong>：在每一层中，添加两个可训练的低秩矩阵 A 和 B，使得权重更新可以表示为 $\Delta W &#x3D; A \times B$，其中 A 的维度为 $d \times r$，B 的维度为 $r \times d$，r 是远小于 d 的秩。</li>
<li><strong>训练低秩矩阵</strong>：仅训练 A 和 B 两个矩阵，其他参数保持不变。</li>
<li><strong>推理阶段</strong>：在推理时，将 $\Delta W$ 加到原始权重上，得到更新后的权重。</li>
</ol>
<p>这种方法的优势在于，只需训练少量参数即可实现模型的适配，极大地降低了计算成本。</p>
<h2 id="实验设置与结果"><a href="#实验设置与结果" class="headerlink" title="实验设置与结果"></a>实验设置与结果</h2><p>研究团队在多个模型和任务上对 LoRA 进行了评估，包括 RoBERTa、DeBERTa、GPT-2 和 GPT-3。实验结果表明，LoRA 在以下方面表现出色：</p>
<ul>
<li><strong>参数效率</strong>：在 GPT-3 175B 上，LoRA 将可训练参数数量减少了约 10,000 倍。</li>
<li><strong>内存使用</strong>：GPU 内存需求降低了约 3 倍。</li>
<li><strong>性能表现</strong>：在多个任务上，LoRA 的性能与全量微调相当，甚至更优。</li>
</ul>
<p>此外，LoRA 的训练吞吐量更高，且在推理阶段不会引入额外的延迟。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>LoRA 提供了一种高效的微调大型语言模型的方法，显著降低了计算资源的需求，同时保持了模型的性能。其核心思想是利用低秩矩阵近似参数更新，从而实现参数高效的微调。</p>
<h2 id="如何使用"><a href="#如何使用" class="headerlink" title="如何使用"></a>如何使用</h2><p>在实践中，使用 LoRA（Low-Rank Adaptation）对大型语言模型进行高效微调，可以显著减少训练所需的参数和计算资源。以下是一个典型的 LoRA 微调流程，适用于如 LLaMA、GPT-2、BERT 等模型，结合了 Hugging Face Transformers 和 PEFT（Parameter-Efficient Fine-Tuning）库的使用。</p>
<h3 id="1-安装必要的库"><a href="#1-安装必要的库" class="headerlink" title="1. 安装必要的库"></a>1. 安装必要的库</h3><p>确保安装了以下 Python 库：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torch transformers datasets peft</span><br></pre></td></tr></table></figure>

<h3 id="2-加载预训练模型和分词器"><a href="#2-加载预训练模型和分词器" class="headerlink" title="2. 加载预训练模型和分词器"></a>2. 加载预训练模型和分词器</h3><p>以 LLaMA 模型为例，加载预训练模型和对应的分词器：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForCausalLM</span><br><span class="line"></span><br><span class="line">model_name = <span class="string">&quot;huggingface/llama-7b&quot;</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_name)</span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(model_name)</span><br></pre></td></tr></table></figure>

<h3 id="3-应用-LoRA-配置"><a href="#3-应用-LoRA-配置" class="headerlink" title="3. 应用 LoRA 配置"></a>3. 应用 LoRA 配置</h3><p>使用 PEFT 库配置 LoRA 参数，并将其应用到模型中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> get_peft_model, LoraConfig, TaskType</span><br><span class="line"></span><br><span class="line">lora_config = LoraConfig(</span><br><span class="line">    r=<span class="number">8</span>,</span><br><span class="line">    lora_alpha=<span class="number">16</span>,</span><br><span class="line">    target_modules=[<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>],</span><br><span class="line">    lora_dropout=<span class="number">0.05</span>,</span><br><span class="line">    bias=<span class="string">&quot;none&quot;</span>,</span><br><span class="line">    task_type=TaskType.CAUSAL_LM</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model = get_peft_model(model, lora_config)</span><br></pre></td></tr></table></figure>

<p>在此配置中：</p>
<ul>
<li><code>r</code>：低秩矩阵的秩，控制参数的压缩程度。</li>
<li><code>lora_alpha</code>：缩放因子，影响学习速率。</li>
<li><code>target_modules</code>：指定应用 LoRA 的模块，通常选择自注意力机制中的查询（q_proj）和键（v_proj）投影层。</li>
</ul>
<h3 id="4-冻结原始模型参数"><a href="#4-冻结原始模型参数" class="headerlink" title="4. 冻结原始模型参数"></a>4. 冻结原始模型参数</h3><p>为了实现参数高效微调，冻结预训练模型的原始参数，仅训练 LoRA 模块的参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model.base_model.parameters():</span><br><span class="line">    param.requires_grad = <span class="literal">False</span></span><br></pre></td></tr></table></figure>

<h3 id="5-准备训练数据"><a href="#5-准备训练数据" class="headerlink" title="5. 准备训练数据"></a>5. 准备训练数据</h3><p>使用 Hugging Face 的 <code>datasets</code> 库加载和预处理训练数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;your_dataset_name&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>根据任务需求，进行必要的数据清洗和格式转换。</p>
<h3 id="6-定义训练参数和训练器"><a href="#6-定义训练参数和训练器" class="headerlink" title="6. 定义训练参数和训练器"></a>6. 定义训练参数和训练器</h3><p>设置训练参数，并使用 <code>Trainer</code> 进行模型训练：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> Trainer, TrainingArguments</span><br><span class="line"></span><br><span class="line">training_args = TrainingArguments(</span><br><span class="line">    output_dir=<span class="string">&quot;./lora-llama&quot;</span>,</span><br><span class="line">    per_device_train_batch_size=<span class="number">4</span>,</span><br><span class="line">    num_train_epochs=<span class="number">3</span>,</span><br><span class="line">    learning_rate=<span class="number">1e-4</span>,</span><br><span class="line">    logging_dir=<span class="string">&quot;./logs&quot;</span>,</span><br><span class="line">    save_total_limit=<span class="number">2</span>,</span><br><span class="line">    save_steps=<span class="number">500</span>,</span><br><span class="line">    evaluation_strategy=<span class="string">&quot;steps&quot;</span>,</span><br><span class="line">    eval_steps=<span class="number">500</span>,</span><br><span class="line">    logging_steps=<span class="number">100</span>,</span><br><span class="line">    load_best_model_at_end=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model=model,</span><br><span class="line">    args=training_args,</span><br><span class="line">    train_dataset=dataset[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    eval_dataset=dataset[<span class="string">&quot;validation&quot;</span>],</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h3 id="7-开始训练"><a href="#7-开始训练" class="headerlink" title="7. 开始训练"></a>7. 开始训练</h3><p>启动训练过程：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trainer.train()</span><br></pre></td></tr></table></figure>

<h3 id="8-保存和加载-LoRA-模型"><a href="#8-保存和加载-LoRA-模型" class="headerlink" title="8. 保存和加载 LoRA 模型"></a>8. 保存和加载 LoRA 模型</h3><p>训练完成后，保存 LoRA 模型的权重：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.save_pretrained(<span class="string">&quot;lora-llama&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>在需要时，加载保存的模型进行推理或进一步训练：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> PeftModel</span><br><span class="line"></span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(model_name)</span><br><span class="line">model = PeftModel.from_pretrained(model, <span class="string">&quot;lora-llama&quot;</span>)</span><br></pre></td></tr></table></figure>


      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LLM/" rel="tag">LLM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LoRA/" rel="tag">LoRA</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%BE%AE%E8%B0%83/" rel="tag">微调</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-大一总结" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2025/05/28/%E5%A4%A7%E4%B8%80%E6%80%BB%E7%BB%93/" class="article-date">
      <time datetime="2025-05-28T07:55:15.000Z" itemprop="datePublished">2025-05-28</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/05/28/%E5%A4%A7%E4%B8%80%E6%80%BB%E7%BB%93/">大一总结</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>今天是5月28号，上大学也快一年了，今天有点闲工夫，写一点随笔。</p>
<p>正好距离高考还有10天，一下子都快要给学弟学妹介绍成电了，都快成大二的老东西了hhh，正好总结一下大一快一年的生活，</p>
<p>其实有很多时候，我感觉大学生活也不是我高三那个时候想象的那么那么那么好，有挺多烦心事的（好吧，大多数时候都是自己给自己找不痛快），哎呀，不过从某些角度上来看，也确实是这些烦心事促进我成长？也有道理吧，我确实会这么认为。</p>
<p>哎呦，真快过一年了，这一年我干什么了呢？</p>
<p>上了教室内的课，拿了挺多学分的，上学期的绩点和均分也挺好看的，也算是没辜负自己的努力，（不过实用的东西好像真没有）。</p>
<p>加入链时代工作室，在三教（马上就是其他地方了）有了个自己的位置沉浸式干自己的事情，未来和室友们一起打比赛！</p>
<p>结交了几个朋友，人都挺好挺真诚的。</p>
<p>参加了些水赛体验体验了，拿了个蓝桥杯省二，现在还在准备银杏果、PAT乙级考试和睿抗，唉唉，希望之后的比赛不要犯像今年蓝桥杯的弱智错误哈哈哈哈哈。</p>
<p>最近学长邀请我给他们的科研项目帮忙跑实验（这还真是算是武侠小说的奇遇了，不然哪能接触到这些），这个哥哥人真的挺好的，能给一个素未谋面的小东西热情的讲那么多，能带我玩。真挺感动的。再过两年我估计就成了带小东西玩的老登了哈哈哈哈哈，传承之力！</p>
<p>成功当上了入党积极分子，这个确实是一直向往的，希望早点进入下一阶段。</p>
<p>课外学习的话，学了一些ml的皮毛东西，跑了几个入门级别的项目，看了几篇经典论文，懂了点理论知识，算是开了个好头吧，希望今后继续深耕，学更多东西，做更多项目，感觉学这些还是挺有意思的，挺有成就感。</p>
<p>课外生活的话，在成都还是逛了个七七八八，在地铁站被骗子骗了80块（其实他一开始只要72块买车票的，结果我想着给人家路上吃点饭多给八块哈哈哈哈哈）。社会上不平等现象还是见识不少，唉，我也改变不了什么。还有就是参加了挺多时间的志愿服务的，还是很有成就感。献了一次血，希望能帮到别人。捐了200块，希望能真的帮到小朋友们。甚至还去少儿编程培训机构免费当了一天劳动力哈哈哈哈哈，我都懒得说哈哈哈哈哈。</p>
<p>还有就是跟女朋友感情挺棒的，嘿嘿，一直挺幸福的，都三年半了嘿嘿嘿嘿嘿嘿。</p>
<p>总的来说过去一年过的还算是挺充实的，虽然有的时候蓦然回首也不知道自己在忙什么，未来要往哪走也说不清楚，至少要比高三的时候迷茫吧。</p>
<p>挺好的挺好的。</p>
<p>过去一年也有不少打击。压力有的时候也挺大的。有的时候天马行空，想起一出是一出，最后还是自己给自己找不痛快。担忧的太多。想得太多。想得太远。希望未来改正。</p>
<p>总的来说，张淞博过去一年过得还算是不错，少了挺多幼稚，学了挺多东西的（知识上和精神上），总体上还算是差强人意吧。</p>
<p>接下来希望能保持奋斗精神，不断寻找局部最优解，向前向前，继续不断夺取革命胜利。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/%E7%94%9F%E6%B4%BB%E9%9A%8F%E8%AE%B0/">生活随记</a>
    </div>


      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Building-Cooperative-Embodied-Agents-Modularly-with-Large-Language-Models" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2025/05/27/Building-Cooperative-Embodied-Agents-Modularly-with-Large-Language-Models/" class="article-date">
      <time datetime="2025-05-27T11:49:42.000Z" itemprop="datePublished">2025-05-27</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/05/27/Building-Cooperative-Embodied-Agents-Modularly-with-Large-Language-Models/">Building Cooperative Embodied Agents Modularly with Large Language Models</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="Building-Cooperative-Embodied-Agents-Modularly-with-Large-Language-Models"><a href="#Building-Cooperative-Embodied-Agents-Modularly-with-Large-Language-Models" class="headerlink" title="Building Cooperative Embodied Agents Modularly with Large Language Models"></a>Building Cooperative Embodied Agents Modularly with Large Language Models</h1><p>原论文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2307.02485">arXiv:2307.02485</a><br> 项目主页：<a target="_blank" rel="noopener" href="https://vis-www.cs.umass.edu/Co-LLM-Agents/">CoELA Project</a></p>
<h2 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h2><p>在多智能体系统中，实现高效的协作一直是一个挑战，尤其是在具身环境中，智能体需要处理原始感知数据、分布式控制以及昂贵的通信成本。传统方法通常依赖于中心化控制或假设通信是无成本的，这在现实中难以实现。</p>
<p>大型语言模型（LLMs）在自然语言理解和生成方面表现出色，具备丰富的常识知识和推理能力。本研究旨在探索如何将LLMs无缝集成到具身智能体中，赋予其计划、沟通和协作的能力，从而高效地完成复杂的长期任务。</p>
<h2 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h2><p>论文提出了一个认知启发的模块化框架，构建了协作型具身语言智能体（Cooperative Embodied Language Agent，简称CoELA）。该框架结合了感知、记忆和执行模块，并利用LLMs的语言理解和生成能力，实现了以下目标：</p>
<ul>
<li><strong>计划能力</strong>：基于当前环境和记忆，生成高层次的行动计划。</li>
<li><strong>沟通能力</strong>：通过自然语言与其他智能体交流，协调任务分工。</li>
<li><strong>协作能力</strong>：与其他智能体共同完成复杂的长期任务。</li>
</ul>
<h2 id="方法流程详解"><a href="#方法流程详解" class="headerlink" title="方法流程详解"></a>方法流程详解</h2><p>在每个交互步骤中，CoELA 首先使用**（a）感知模块<strong>感知从环境中接收到的原始感官观察信息，然后用提取的新信息更新</strong>（b）记忆模块**，该模块存储了它对世界和他人的知识和经验。CoELA 采用两步法应对高效通信的挑战：首先决定发送什么信息，然后决定是发送该信息还是选择其他方案，具体方法是特意使用 <strong>(c) 通信模块</strong>从 <strong>(b) 模块</strong>中检索相关信息，并利用 LLM 事先在 “头脑中 ”生成要发送的最佳信息，然后利用 LLM 驱动的具有强大推理能力的 <strong>(d) 规划模块</strong>，根据从 <strong>(b) 模块</strong>中检索的相关信息和针对当前状态提出的可用行动，决定采取哪种方案。生成的计划随后用于更新 <strong>(b2) 事件记忆</strong>。最后，<strong>(e) 执行模块</strong>检索 <strong>(b3)</strong> 中存储的程序知识，将高级计划转化为可在环境中执行的基本行动。</p>
<p>CoELA框架由以下五个关键模块组成：</p>
<h3 id="感知模块（Perception-Module）"><a href="#感知模块（Perception-Module）" class="headerlink" title="感知模块（Perception Module）"></a>感知模块（Perception Module）</h3><p>处理来自环境的原始感知数据，如视觉信息，提取有用的特征供后续模块使用。</p>
<p>直接处理从环境中接收到的复杂视觉观测信息，通过训练 Mask-RCNN 来预测 RGB 图像中的分割掩码，然后利用 RGB-D 图像构建三维点云，提取有用的高级信息，如关键物体的状态，并构建局部语义图。</p>
<h3 id="记忆模块（Belief-Module）"><a href="#记忆模块（Belief-Module）" class="headerlink" title="记忆模块（Belief Module）"></a>记忆模块（Belief Module）</h3><p>维护智能体对环境和其他智能体状态的内部表示，更新对世界的理解。模仿人类的长期记忆，为 CoELA 设计了<strong>语义记忆</strong>、<strong>情节记忆</strong>和<strong>程序记忆</strong>。</p>
<h4 id="语义记忆"><a href="#语义记忆" class="headerlink" title="语义记忆"></a>语义记忆</h4><p>存储了 CoELA 关于世界的知识，包括语义地图、任务进度、自身状态和他人状态。每当感知模型接收并感知到新的观察结果时，语义记忆就会相应地更新。需要注意的是，CoELA 对世界的了解可能并不准确，因为其他智能体可能会与对象进行交互，并在其不知情的情况下改变对象的状态。处理记忆与他人对世界的描述之间的不一致性也增加了更多的挑战。</p>
<h4 id="情节记忆"><a href="#情节记忆" class="headerlink" title="情节记忆"></a>情节记忆</h4><p>存储了 CoELA 过去的经验，包括行动历史和对话历史。每当 CoELA 执行一项新的操作（包括发送信息或接收新信息）时，相关信息就会被添加到外显记忆中。 </p>
<h4 id="程序记忆"><a href="#程序记忆" class="headerlink" title="程序记忆"></a>程序记忆</h4><p>包含的知识包括如何在特定环境中执行以代码和神经模型参数实现的特定高级计划。</p>
<h3 id="通信模块（Communication-Module）"><a href="#通信模块（Communication-Module）" class="headerlink" title="通信模块（Communication Module）"></a>通信模块（Communication Module）</h3><p>利用LLMs生成自然语言消息，与其他智能体共享信息，协调行动。</p>
<p>为了让智能体更好地完成合作任务，避免低效的闲聊，通信模块首先从记忆模块中获取相关信息，包括语义图、任务进度、智能体状态、他人状态、行动和对话历史等，然后利用模板将这些信息转化为文本描述，最后提示智能体将指令头、目标描述、状态描述、行动历史和对话历史串联起来，生成要发送的信息。</p>
<h3 id="规划模块（Planning-Module）"><a href="#规划模块（Planning-Module）" class="headerlink" title="规划模块（Planning Module）"></a>规划模块（Planning Module）</h3><p>整合来自感知、记忆和通信模块的信息，进行高层次的推理和决策。</p>
<p>CoELA 需要一个强大的规划模块，以利用迄今为止收集和存储的所有可用信息来决定采取何种行动，从而最大限度地提高合作效率。</p>
<p>直接利用强大的 LLM 作为规划模块，首先从内存模块中检索相关信息，并将其转换为文本描述，就像在通信模块中一样、 然后，根据当前状态和存储的程序知识，将所有可用的高级计划建议汇编成一个行动列表，供 LLMs 进行选择。最后，根据当前信息和建议的行动列表提示 LLMs 生成高级计划。</p>
<p>采用零样本思维链提示技术，鼓励 LLM 在给出最终答案前进行更多推理。</p>
<h3 id="执行模块（Execution-Module）"><a href="#执行模块（Execution-Module）" class="headerlink" title="执行模块（Execution Module）"></a>执行模块（Execution Module）</h3><p>基于推理结果，制定具体的行动计划，并指导执行模块完成任务。</p>
<p>为了在不同环境中实现有效和通用的合作决策，设计了一个执行模块来生成原始行动，以便在特定环境中稳健地执行给定的高层次计划，从而使规划模块具有通用性，并利用 LLMs 丰富的世界知识和强大的推理能力，更加专注于解决整体任务。这种设计还能减少 LLM 的推理时间，省时又经济。CoELA 会检索记忆模块中与规划模块生成的计划相关的程序，然后用适合环境的原始动作执行程序。</p>
<p>整个流程如下图所示：</p>
<p><img src="D:\blog\source\img\具身智能体" alt="image-20250528200144004"></p>
<h2 id="实验设置与结果"><a href="#实验设置与结果" class="headerlink" title="实验设置与结果"></a>实验设置与结果</h2><p>研究团队在两个具身多智能体协作环境中对CoELA进行了评估：</p>
<ul>
<li><strong>C-WAH（Communicative Watch-And-Help）</strong>：智能体需要通过沟通协作完成观察和帮助任务。</li>
<li><strong>TDW-MAT（ThreeDWorld Multi-Agent Transport）</strong>：智能体需要协同搬运物体，完成运输任务。</li>
</ul>
<p>实验结果表明，基于GPT-4的CoELA在任务完成率和协作效率方面均优于传统的基于规划的方法。此外，CoELA展现出自发的有效沟通能力，能够通过自然语言与其他智能体协调行动。</p>
<p>研究还对CoELA与人类的交互进行了用户研究，发现使用自然语言进行沟通的CoELA更容易获得人类的信任，并能更有效地与人类协作完成任务。</p>
<h2 id="与现有方法的对比"><a href="#与现有方法的对比" class="headerlink" title="与现有方法的对比"></a>与现有方法的对比</h2><p>传统的多智能体协作方法通常依赖于中心化控制或预定义的通信协议，缺乏灵活性和适应性。CoELA通过引入LLMs，实现了以下优势：</p>
<ul>
<li><strong>去中心化控制</strong>：每个智能体独立运行，通过自然语言进行协调，无需中心化指挥。</li>
<li><strong>灵活的沟通机制</strong>：利用LLMs的语言生成能力，实现了灵活且高效的沟通。</li>
<li><strong>可扩展性强</strong>：模块化设计使得系统易于扩展和适应不同的任务和环境。</li>
</ul>
<p>此外，CoELA还展示了与人类协作的潜力，为人机协作提供了新的可能性。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本研究提出的CoELA框架展示了将大型语言模型集成到具身智能体中，以实现高效多智能体协作的可能性。通过模块化设计和自然语言沟通，CoELA在复杂任务中表现出色，并展现出与人类协作的潜力。</p>
<p>未来的研究方向可能包括：</p>
<ul>
<li><strong>增强感知能力</strong>：结合多模态感知，提高智能体对环境的理解能力。</li>
<li><strong>优化沟通策略</strong>：研究更高效的沟通协议，减少通信成本。</li>
<li><strong>扩展应用场景</strong>：将CoELA应用于更多实际场景，如灾难救援、智能制造等。</li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LLM/" rel="tag">LLM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/agent/" rel="tag">agent</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/multi-agent/" rel="tag">multi-agent</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%85%B7%E8%BA%AB%E6%99%BA%E8%83%BD/" rel="tag">具身智能</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Generative_Agents_Interactive_Simulacra_of_Human_Behavior" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2025/05/26/Generative_Agents_Interactive_Simulacra_of_Human_Behavior/" class="article-date">
      <time datetime="2025-05-26T09:02:58.000Z" itemprop="datePublished">2025-05-26</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/05/26/Generative_Agents_Interactive_Simulacra_of_Human_Behavior/">Generative Agents Interactive Simulacra of Human Behavior</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="Generative-Agents-Interactive-Simulacra-of-Human-Behavior"><a href="#Generative-Agents-Interactive-Simulacra-of-Human-Behavior" class="headerlink" title="Generative Agents: Interactive Simulacra of Human Behavior"></a>Generative Agents: Interactive Simulacra of Human Behavior</h1><p>原论文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2304.03442">Generative Agents: Interactive Simulacra of Human Behavior</a></p>
<blockquote>
<p>通过生成式智能体，我们迈出了构建虚拟社会的第一步。</p>
</blockquote>
<h2 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h2><p>随着大型语言模型（LLM）的发展，构建能够模拟人类行为的智能体成为可能。传统的非玩家角色（NPC）行为通常是预定义的，缺乏灵活性和真实感。本研究旨在探索如何利用LLM创建具备记忆、反思和规划能力的生成式智能体，以实现更逼真的人类行为模拟。</p>
<h2 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h2><p>论文提出了一种生成式智能体架构，结合LLM的语言生成能力和智能体的行为规划机制，使得智能体能够：</p>
<ul>
<li>记录和存储自然语言形式的经历；</li>
<li>对过去的经历进行反思，形成高层次的见解；</li>
<li>基于当前环境和记忆，动态规划未来的行为。</li>
</ul>
<p>通过这种方式，智能体能够在虚拟环境中表现出类似人类的日常行为和社交互动。</p>
<h2 id="智能体架构"><a href="#智能体架构" class="headerlink" title="智能体架构"></a>智能体架构</h2><p>生成式智能体的架构包括以下关键组件：</p>
<h3 id="1-记忆模块（Memory-and-Retrieval）"><a href="#1-记忆模块（Memory-and-Retrieval）" class="headerlink" title="1. 记忆模块（Memory and Retrieval）"></a>1. 记忆模块（Memory and Retrieval）</h3><p>智能体以自然语言的形式记录其经历，包括事件、对话和观察结果。这些记忆带有时间戳，并存储在一个可查询的数据库中。</p>
<p>例如，在咖啡店工作的伊莎贝拉-罗德里格斯（Isabella Rodriguez）可能会随着时间的推移积累以下观察结果：(1) 伊莎贝拉-罗德里格斯正在摆放糕点；(2) 玛丽亚-洛佩兹（Maria Lopez）正在一边喝咖啡一边准备化学考试；(3) 伊莎贝拉-罗德里格斯和玛丽亚-洛佩兹（Maria Lopez）正在谈论在霍布斯咖啡馆举办情人节派对的计划；(4) 冰箱是空的。</p>
<p>每个当前决定的事件通过以下三个数据进行计算，在语言模型的上下文窗口中排名靠前的记忆会被纳入提示。</p>
<p>使用 minmax 缩放法将<em><strong>Recency</strong></em> 、<em><strong>Importance</strong></em> 和<em><strong>Relevance</strong></em> 得分归一到 [0, 1] 的范围内。检索函数以三个元素的加权组合对所有记忆进行评分.</p>
<p><em><strong>Recency</strong></em> 给最近访问过的记忆对象分配更高的分数，因此智能体的注意力范围内很可能还保留着刚才或今天上午发生的事件。它通过指数衰减函数实现</p>
<p><em><strong>Importance</strong></em> 通过给智能体认为重要的记忆对象打高分，来区分平凡记忆和核心记忆。例如，在房间里吃早餐等平凡事件的重要性得分较低，而与另一半分手的事件的重要性得分较高。它通过让 LLM 直接输出一个整数分数来实现。</p>
<p><em><strong>Relevance</strong></em> 是与当前情况相关的记忆对象赋予更高的分数。什么是相关性取决于对 “与什么相关？”的回答，因此我们将查询记忆作为相关性的条件。在实施过程中，使用语言模型生成每个记忆的文本描述的嵌入向量。然后，用记忆的嵌入向量和查询记忆的嵌入向量之间的余弦相似度来计算相关性。</p>
<h3 id="2-反思模块（Reflection）"><a href="#2-反思模块（Reflection）" class="headerlink" title="2. 反思模块（Reflection）"></a>2. 反思模块（Reflection）</h3><p> 当智能体只有原始的观察记忆时，很难进行归纳或推理。</p>
<p>智能体定期对其记忆进行反思，识别出关键事件和模式，形成更高层次的见解。这些反思有助于智能体在未来的行为中做出更合理的决策。</p>
<p>反思的第一步是让智能体根据最近的经历确定可以提出的问题，从而确定反思的内容。我们用智能体记忆流中最近的 100 条记录查询大型语言模型（例如，“克劳斯-穆勒正在阅读一本关于城市化的书”、“克劳斯-穆勒正在与图书管理员谈论他的研究项目”、“图书馆的桌子目前无人使用”），并提示语言模型：”<strong>仅根据上述信息，我们可以回答关于语句中的主题的 3 个最突出的高层次问题是什么？</strong>” 模型的回答会生成候选问题：例如，克劳斯-穆勒热衷于什么话题？ 克劳斯-穆勒和玛丽亚-洛佩兹之间是什么关系？我们将这些生成的问题作为检索查询，并收集每个问题的相关记忆（包括其他思考）。然后，我们提示语言模型提取见解，并引用作为见解证据的特定记录。</p>
<p>最终，智能体生成反思树：树的叶节点代表基础观察，非叶节点代表思考，越往上越抽象，层次越高。</p>
<h3 id="3-行为规划与执行模块（Planning-and-Reacting）"><a href="#3-行为规划与执行模块（Planning-and-Reacting）" class="headerlink" title="3. 行为规划与执行模块（Planning and Reacting）"></a>3. 行为规划与执行模块（Planning and Reacting）</h3><p>智能体基于当前的环境状态和记忆，使用LLM生成行动计划。计划从高层次的日程安排开始，逐步细化到具体的行为步骤。</p>
<p>计划描述了智能体未来的行动序列，有助于使智能体的行为在一段时间内保持一致。与思考一样，计划也存储在记忆流中，并包含在检索过程中。这样，智能体在决定如何行动时，就能将观察、思考和计划一并考虑在内。如有需要，智能体可以中途改变计划。</p>
<p>智能体根据生成的计划执行行为，并将新的经历记录到记忆中，形成闭环。</p>
<p>智能体在一个行动循环中运行，在每个时间步骤中，它们都会感知周围的世界，这些感知到的观察结果会存储在它们的记忆流中。我们用这些观察结果提示语言模型，以决定智能体是继续执行现有计划，还是做出反应。</p>
<h2 id="实验设置与结果"><a href="#实验设置与结果" class="headerlink" title="实验设置与结果"></a>实验设置与结果</h2><p>研究团队在一个受《模拟人生》启发的虚拟小镇中部署了25个生成式智能体。用户可以通过自然语言与这些智能体交互，观察其行为和社交互动。</p>
<p>实验结果显示，智能体能够：</p>
<ul>
<li>自主生成日常行为，如起床、吃饭、工作等；</li>
<li>与其他智能体建立关系，进行对话；</li>
<li>组织和参与社交活动，如派对。</li>
</ul>
<p>例如，当用户建议一个智能体举办情人节派对时，智能体会主动邀请其他智能体，协调时间和地点，并最终成功举办派对。</p>
<h2 id="与现有方法的对比"><a href="#与现有方法的对比" class="headerlink" title="与现有方法的对比"></a>与现有方法的对比</h2><p>传统的NPC行为通常是基于规则或有限状态机，缺乏灵活性和适应性。而生成式智能体利用LLM的语言生成能力和记忆、反思机制，实现了更真实和多样化的行为表现。</p>
<p>此外，生成式智能体的行为是可解释的，因为其决策过程基于可查询的自然语言记忆和反思结果。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本研究展示了结合LLM和智能体架构，创建能够模拟人类行为的生成式智能体的可能性。这些智能体在虚拟环境中表现出逼真的个体行为和社交互动，具有广泛的应用前景，如虚拟助手、游戏NPC、社交模拟等。</p>
<p>未来的研究方向可能包括：</p>
<ul>
<li>扩展智能体的数量和多样性，模拟更复杂的社会结构；</li>
<li>引入情感和价值观模型，增强智能体的个性化行为；</li>
<li>探索生成式智能体在教育、培训和心理健康等领域的应用。</li>
</ul>
<hr>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LLM/" rel="tag">LLM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/agent/" rel="tag">agent</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%A8%A1%E6%8B%9F%E4%BA%BA%E7%B1%BB%E8%A1%8C%E4%B8%BA/" rel="tag">模拟人类行为</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-HuggingGPT-Solving-AI-Tasks-with-ChatGPT-and-its-Friends-in-Hugging-Face" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2025/05/26/HuggingGPT-Solving-AI-Tasks-with-ChatGPT-and-its-Friends-in-Hugging-Face/" class="article-date">
      <time datetime="2025-05-26T02:23:21.000Z" itemprop="datePublished">2025-05-26</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/05/26/HuggingGPT-Solving-AI-Tasks-with-ChatGPT-and-its-Friends-in-Hugging-Face/">HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="HuggingGPT-Solving-AI-Tasks-with-ChatGPT-and-its-Friends-in-Hugging-Face"><a href="#HuggingGPT-Solving-AI-Tasks-with-ChatGPT-and-its-Friends-in-Hugging-Face" class="headerlink" title="HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face"></a>HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face</h1><blockquote>
<p>“拥有许多特定技能的专家”转向“一个能够理解问题并指挥这些专家协同工作的智能协调者”。</p>
</blockquote>
<p>HuggingGPT 提出了一种新的AI任务解决框架。这个框架的核心思想是<strong>利用LLM作为控制器，来协调和管理 Hugging Face 中丰富的预训练模型，从而解决复杂的人工智能任务。</strong></p>
<p>可以将 HuggingGPT 想象成一个**“AI 任务的总调度师”**。当用户提出一个复杂的需求时，HuggingGPT 会：</p>
<ol>
<li><strong>理解任务 (Task Planning)：</strong> 首先，ChatGPT 会分析用户的请求，将其分解成若干个可以由特定 AI 模型解决的子任务。</li>
<li><strong>选择模型 (Model Selection)：</strong> 接着，ChatGPT 会根据每个子任务的特性，在庞大的 Hugging Face 模型库中选择最合适的模型。Hugging Face 提供了数以万计的针对不同模态（文本、图像、音频、视频等）和不同任务（分类、生成、问答、翻译等）的预训练模型。</li>
<li><strong>执行任务 (Task Execution)：</strong> 选定的模型会被调用来执行各自的子任务。这可能涉及到模型的下载、参数配置和推理运行。</li>
<li><strong>整合结果 (Response Generation)：</strong> 最后，ChatGPT 会将各个模型执行的结果整合起来，生成一个统一的、连贯的答案回复给用户。</li>
</ol>
<p><strong>核心优势：</strong></p>
<ul>
<li><strong>强大的任务分解与规划能力：</strong> 借助 ChatGPT 的自然语言理解和推理能力，HuggingGPT 能够理解复杂的用户意图，并将其有效地分解为可执行的步骤。</li>
<li><strong>海量的模型资源：</strong> 通过接入 Hugging Face，HuggingGPT 可以利用社区中几乎所有公开的预训练模型，极大地扩展了其解决问题的能力和范围。</li>
<li><strong>多模态处理：</strong> Hugging Face 包含了处理文本、图像、音频、视频等多种数据类型的模型，使得 HuggingGPT 能够处理涉及多种信息模态的复杂任务。</li>
<li><strong>灵活性和可扩展性：</strong> 随着 Hugging Face 社区模型的不断增加和 ChatGPT 能力的持续提升，HuggingGPT 的能力也会随之增强。</li>
</ul>
<p><strong>工作流程详解：</strong></p>
<p>通过一个具体的例子来理解 HuggingGPT 的工作流程。</p>
<p><strong>用户请求：</strong> “请帮我生成一张图片，图片中有一只戴着宇航员头盔的猫在月球上，并且告诉我这张图片描述了什么。”</p>
<p><strong>HuggingGPT 的处理步骤：</strong></p>
<ol>
<li><strong>任务规划 (Task Planning - by ChatGPT)：</strong><ul>
<li>ChatGPT 首先解析用户的请求，识别出这是一个包含多个子任务的复杂需求。</li>
<li>它会将其分解为：<ul>
<li><strong>子任务1 (图像生成)：</strong> 根据文本描述 “一只戴着宇航员头盔的猫在月球上” 生成一张图片。</li>
<li><strong>子任务2 (图像描述)：</strong> 对生成的图片进行描述。</li>
</ul>
</li>
</ul>
</li>
<li><strong>模型选择 (Model Selection - by ChatGPT with Hugging Face API)：</strong><ul>
<li><strong>对于子任务1 (图像生成)：</strong> ChatGPT 会查询 Hugging Face 模型库，寻找能够执行“文本到图像生成 (text-to-image generation)”任务的模型。它可能会找到像 <code>Stable Diffusion</code> 或 <code>DALL-E 2</code> (如果可以通过 Hugging Face 访问其变体或类似模型) 这样的模型。假设它选择了 <code>runwayml/stable-diffusion-v1-5</code>。</li>
<li><strong>对于子任务2 (图像描述)：</strong> ChatGPT 会查询 Hugging Face 模型库，寻找能够执行“图像到文本描述 (image-to-text captioning)”任务的模型。它可能会找到像 <code>Salesforce/blip-image-captioning-large</code> 或 <code>microsoft/git-large-coco</code> 这样的模型。假设它选择了 <code>nlpconnect/vit-gpt2-image-captioning</code>。</li>
</ul>
</li>
<li><strong>任务执行 (Task Execution - by Selected Hugging Face Models)：</strong><ul>
<li>执行子任务1：<ul>
<li>HuggingGPT 将文本描述 “一只戴着宇航员头盔的猫在月球上” 作为输入，传递给选定的文本到图像生成模型 (<code>runwayml/stable-diffusion-v1-5</code>)。</li>
<li>该模型运行推理，生成一张图片。</li>
</ul>
</li>
<li>执行子任务2：<ul>
<li>HuggingGPT 将上一步生成的图片作为输入，传递给选定的图像描述模型 (<code>nlpconnect/vit-gpt2-image-captioning</code>)。</li>
<li>该模型运行推理，生成对这张图片的文本描述，例如：”A cat wearing an astronaut helmet is sitting on the moon.” (一只戴着宇航员头盔的猫坐在月球上。)</li>
</ul>
</li>
</ul>
</li>
<li><strong>结果生成 (Response Generation - by ChatGPT)：</strong><ul>
<li>ChatGPT 收集来自两个子任务的执行结果：<ul>
<li>结果1: 生成的图片文件。</li>
<li>结果2: 文本描述 “A cat wearing an astronaut helmet is sitting on the moon.”</li>
</ul>
</li>
<li>ChatGPT 将这些结果整合起来，形成一个对用户友好的回复：<ul>
<li>“好的，这是您要求的图片：[展示生成的图片]”</li>
<li>“这张图片描述的是：一只戴着宇航员头盔的猫坐在月球上。”</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><strong>另一个例子（更复杂）：</strong></p>
<p><strong>用户请求：</strong> “我有一段关于气候变化的英文演讲稿（提供文本文件），请帮我把它翻译成中文，然后总结出主要观点，并生成一个三分钟的音频摘要。”</p>
<p><strong>HuggingGPT 的处理步骤：</strong></p>
<ol>
<li><strong>任务规划：</strong><ul>
<li>子任务1: 文本翻译 (英语到中文)。</li>
<li>子任务2: 文本摘要 (对翻译后的中文文本进行摘要)。</li>
<li>子任务3: 文本到语音合成 (将中文摘要转换为音频)。</li>
</ul>
</li>
<li><strong>模型选择：</strong><ul>
<li>子任务1: 选择一个英译中翻译模型 (例如 <code>Helsinki-NLP/opus-mt-en-zh</code>)。</li>
<li>子任务2: 选择一个中文文本摘要模型 (例如 <code>csebuetnlp/mT5_multilingual_XLSum</code>，虽然是多语言，但可以用于中文)。</li>
<li>子任务3: 选择一个中文文本到语音合成模型 (例如 <code>microsoft/speecht5_tts</code> 配合中文 vocoder)。</li>
</ul>
</li>
<li><strong>任务执行：</strong><ul>
<li>执行翻译，得到中文演讲稿。</li>
<li>对中文演讲稿进行摘要，得到主要观点。</li>
<li>将中文摘要转换为音频文件。</li>
</ul>
</li>
<li><strong>结果生成：</strong><ul>
<li>ChatGPT 返回：<ul>
<li>翻译后的中文演讲稿文本。</li>
<li>中文摘要文本。</li>
<li>生成的音频文件。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><strong>HuggingGPT 的意义和影响：</strong></p>
<ul>
<li><strong>降低了复杂 AI 任务的门槛：</strong> 用户不再需要了解具体模型的技术细节，只需用自然语言描述需求。</li>
<li><strong>促进了 AI 模型的组合和复用：</strong> 鼓励开发者将精力集中在构建高质量的单个任务模型上，而 HuggingGPT 则负责将它们有机地组合起来。</li>
<li><strong>为通用人工智能 (AGI) 的探索提供了新的思路：</strong> 虽然距离真正的 AGI 还很遥远，但 HuggingGPT 展示了如何通过大型语言模型的智能调度来整合多个专用 AI 能力，从而解决更广泛、更复杂的问题。</li>
<li><strong>推动了“AI 即服务 (AIaaS)”的发展：</strong> HuggingGPT 的框架可以被视为一种高级的 AI 服务编排系统。</li>
</ul>
<p><strong>局限性：</strong></p>
<ul>
<li><strong>对 ChatGPT 能力的依赖：</strong> 任务分解和模型选择的质量高度依赖于 ChatGPT 的理解和推理能力。如果 ChatGPT 理解错误或选择了不合适的模型，最终结果可能会不理想。</li>
<li><strong>计算资源和效率：</strong> 调用和运行多个大型模型可能会消耗大量的计算资源，并导致较高的延迟。</li>
<li><strong>输入长度限制：</strong> LLM 通常存在最大输入 token 数量的限制。虽然一些先进的 LLM 已经将此限制扩展到了例如 32K，但在需要连接和协调<strong>大量模型</strong>的复杂场景下，这个长度可能仍然<strong>不足以容纳所有必要的模型描述和上下文信息</strong>。</li>
<li><strong>不稳定性与不可控性：</strong> 这种不稳定性主要源于 LLM 本身的特性。尽管 LLM 在内容生成方面表现出色，但在实际推理过程中，它们有时可能<strong>无法严格遵循指令</strong>，或者可能<strong>给出错误的中间答案或判断</strong>。这些不可预测的行为可能导致整个程序工作流程出现异常甚至中断。</li>
</ul>
<p><strong>总结：</strong></p>
<p>HuggingGPT 巧妙地将大型语言模型的认知能力与 Hugging Face 丰富的模型生态结合起来。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
    </div>


      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-ChatEval" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2025/05/25/ChatEval/" class="article-date">
      <time datetime="2025-05-25T08:17:30.000Z" itemprop="datePublished">2025-05-25</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/05/25/ChatEval/">ChatEval</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="CHATEVAL-Towards-Better-LLM-Based-Evaluators-through-Multi-Agent-Debate"><a href="#CHATEVAL-Towards-Better-LLM-Based-Evaluators-through-Multi-Agent-Debate" class="headerlink" title="CHATEVAL: Towards Better LLM-Based Evaluators through Multi-Agent Debate"></a>CHATEVAL: Towards Better LLM-Based Evaluators through Multi-Agent Debate</h1><p>原论文链接 [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2402.04047">2402.04047] ChatEval: Towards Better LLM-Based Evaluators through Multi-Agent Debate</a></p>
<blockquote>
<p>模型评估，或许不应只靠“评分”，更应该是一场“辩论”。</p>
</blockquote>
<h2 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h2><p>随着 LLM 在文本生成、推理等任务上的迅速发展，如何“评估”这些模型的生成质量成为新的挑战。传统自动评估指标（如 BLEU、ROUGE）已无法充分捕捉语义准确性、逻辑一致性等高层次语言特性。</p>
<p>当前主流方法倾向于使用 LLM 充当“评审”来评估其他 LLM 的输出，但这也引入了一个关键问题：<strong>评审模型本身可能带有偏见，甚至会误判</strong>。</p>
<h2 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h2><p>CHATEVAL 借鉴“多智能体辩论（Multi-Agent Debate）”机制，提出使用<strong>多个 LLM 评审 agent 之间的辩论过程</strong>来提升评估的准确性和鲁棒性。</p>
<p>其核心理念是：<strong>让评估者们相互挑战、质疑与辩护，从辩论中收敛出一个更合理、更公平的判断结果。</strong></p>
<hr>
<h2 id="与现有评估框架的对比"><a href="#与现有评估框架的对比" class="headerlink" title="与现有评估框架的对比"></a>与现有评估框架的对比</h2><h3 id="单一模型评估"><a href="#单一模型评估" class="headerlink" title="单一模型评估"></a>单一模型评估</h3><p>该方法使用一个大型语言模型（LLM）对生成内容进行评分。尽管操作简便，但存在以下问题：</p>
<ul>
<li><strong>主观性强</strong>：评估结果容易受到模型自身偏见的影响。</li>
<li><strong>缺乏多样性</strong>：单一视角可能无法全面捕捉生成内容的质量。</li>
<li><strong>可解释性差</strong>：难以提供详细的评分理由。</li>
</ul>
<h3 id="ChatEval-框架"><a href="#ChatEval-框架" class="headerlink" title="ChatEval 框架"></a>ChatEval 框架</h3><p>ChatEval 是一种基于多智能体辩论的评估框架，具有以下特点：</p>
<ul>
<li><strong>多轮辩论</strong>：多个模型之间进行多轮讨论，互相挑战和纠正观点。</li>
<li><strong>通信模式</strong>：引入三种通信模式（逐个发言、同时发言、同时发言并摘要），提高讨论的效率和质量。</li>
<li><strong>元评审者</strong>：引入一个 Meta-Evaluator，综合各模型的观点，给出最终评分和解释。</li>
</ul>
<p>与传统方法相比，ChatEval 在评估的准确性、鲁棒性和可解释性方面表现更优。</p>
<h2 id="方法流程详解"><a href="#方法流程详解" class="headerlink" title="方法流程详解"></a>方法流程详解</h2><p>CHATEVAL 的评估过程主要包括以下三个阶段：</p>
<h3 id="Step-1：多模型初评"><a href="#Step-1：多模型初评" class="headerlink" title="Step 1：多模型初评"></a>Step 1：多模型初评</h3><p>给定一个任务（如生成一段摘要），多个 LLM agent 对候选输出进行评分，并提供理由。</p>
<ul>
<li>每个 agent 提供：<ul>
<li>打分</li>
<li>支持评分的理由</li>
</ul>
</li>
</ul>
<h3 id="Step-2：多轮辩论"><a href="#Step-2：多轮辩论" class="headerlink" title="Step 2：多轮辩论"></a>Step 2：多轮辩论</h3><p>agent 之间进入“辩论”流程，每轮中：</p>
<ul>
<li>Agent A 提出对生成内容的批评或赞同理由；</li>
<li>Agent B 需回应该观点，提出反驳或修正；</li>
<li>每轮都有新的观点加入辩论，使信息不断丰富与澄清。</li>
</ul>
<p>在此过程中，CHATEVAL 提出了三种不同的通信模式，用于组织 agent 之间的交流：</p>
<h4 id="1-One-by-One（逐个发言）"><a href="#1-One-by-One（逐个发言）" class="headerlink" title="1. One-by-One（逐个发言）"></a>1. One-by-One（逐个发言）</h4><p>在每一轮辩论中，agent 按照预定顺序依次发言。每个 agent 在发言时，可以看到之前所有 agent 的发言内容，并在此基础上生成自己的回应。这种方式模拟了传统的逐轮讨论，有助于信息的逐步积累，但可能引入发言顺序带来的偏差。</p>
<h4 id="2-Simultaneous-Talk（同时发言）"><a href="#2-Simultaneous-Talk（同时发言）" class="headerlink" title="2. Simultaneous-Talk（同时发言）"></a>2. Simultaneous-Talk（同时发言）</h4><p>所有 agent 在每一轮中同时生成回应，彼此之间在当前轮次中不共享信息。在下一轮开始前，所有 agent 的发言内容会被汇总，并提供给所有 agent 作为新的上下文。这种方式消除了发言顺序的影响，促进了观点的多样性，但可能导致信息冗余。</p>
<h4 id="3-Simultaneous-Talk-with-Summarizer（同时发言并摘要）"><a href="#3-Simultaneous-Talk-with-Summarizer（同时发言并摘要）" class="headerlink" title="3. Simultaneous-Talk-with-Summarizer（同时发言并摘要）"></a>3. Simultaneous-Talk-with-Summarizer（同时发言并摘要）</h4><p>在 Simultaneous-Talk 的基础上，引入一个额外的 LLM 作为摘要器。在每轮结束时，摘要器对所有 agent 的发言进行总结，并将摘要结果提供给所有 agent 作为下一轮的上下文。这种方式有助于信息的整合和重点突出，减少冗余，提高讨论效率。</p>
<h3 id="Step-3：Meta-Evaluator-裁决"><a href="#Step-3：Meta-Evaluator-裁决" class="headerlink" title="Step 3：Meta-Evaluator 裁决"></a>Step 3：Meta-Evaluator 裁决</h3><p>在多轮辩论结束后，引入一个 Meta-Evaluator：</p>
<ul>
<li>分析所有辩论过程中的观点、反驳和逻辑链；</li>
<li>生成最终的评分与评语；</li>
<li>并解释为何选择该评分（提高透明度）。</li>
</ul>
<h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>CHATEVAL 提供了一种更加“互动式”的 LLM 评估方案，<strong>从静态判断走向动态协商</strong>。通过引入多智能体间的辩论流程，它让每一个评估者“负责任地表达观点”，并最终促成一个更可靠的判断。</p>
<p>值得关注的后续方向包括：</p>
<ul>
<li>如何进一步提升辩论效率（降低成本）；</li>
<li>是否可以将这种辩论机制用于人类-LLM 协同评估；</li>
<li>可否在更复杂任务（如代码生成、数学题评估）中推广此框架。</li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LLM-Evaluation/" rel="tag">LLM Evaluation</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Multi-Agent/" rel="tag">Multi-Agent</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Improving-Factuality-and-Reasoning-in-Language-Models-through-Multiagent-Debate" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2025/05/24/Improving-Factuality-and-Reasoning-in-Language-Models-through-Multiagent-Debate/" class="article-date">
      <time datetime="2025-05-24T12:05:09.000Z" itemprop="datePublished">2025-05-24</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/05/24/Improving-Factuality-and-Reasoning-in-Language-Models-through-Multiagent-Debate/">Improving Factuality and Reasoning in Language Models through Multiagent Debate</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="Improving-Factuality-and-Reasoning-in-Language-Models-through-Multiagent-Debate"><a href="#Improving-Factuality-and-Reasoning-in-Language-Models-through-Multiagent-Debate" class="headerlink" title="Improving Factuality and Reasoning in Language Models through Multiagent Debate"></a>Improving Factuality and Reasoning in Language Models through Multiagent Debate</h1><p>原论文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.14325">arXiv:2305.14325</a><br> 项目主页：<a target="_blank" rel="noopener" href="https://composable-models.github.io/llm_debate/">Multiagent Debate</a></p>
<h2 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h2><p>大型语言模型（LLMs）在自然语言处理任务中表现出色，但仍存在生成内容不准确（hallucination）和推理不严谨的问题。传统方法如Chain-of-Thought（CoT）和Self-Consistency等尝试通过引导模型自我反思来提升性能，但效果有限。提出了一种多智能体辩论（Multi-Agent Debate, MAD）框架，通过多个LLM实例之间的辩论，提升模型的事实性和推理能力。</p>
<h2 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h2><p>MAD框架的核心理念是<strong>模拟人类社会中的辩论机制</strong>，让多个语言模型实例就同一问题进行多轮辩论，通过相互批判和修正，最终达成更准确的共识。这种 “Society of Mind“ 的方式能够有效减少模型的幻觉现象，提升推理的严谨性。</p>
<h2 id="架构设计详解"><a href="#架构设计详解" class="headerlink" title="架构设计详解"></a>架构设计详解</h2><p>MAD框架主要包括以下几个阶段：</p>
<h3 id="1-初始响应生成"><a href="#1-初始响应生成" class="headerlink" title="1. 初始响应生成"></a>1. 初始响应生成</h3><p>每个智能体独立生成对给定问题的初始回答。</p>
<h3 id="2-多轮辩论"><a href="#2-多轮辩论" class="headerlink" title="2. 多轮辩论"></a>2. 多轮辩论</h3><p>在每一轮中，每个智能体都会接收到其他智能体的回答，并基于这些信息更新自己的回答。具体过程如下：</p>
<ul>
<li><strong>输入构建</strong>：将其他智能体的回答拼接成上下文，作为当前智能体的新输入。</li>
<li><strong>更新回答</strong>：智能体根据新的上下文，生成更新后的回答。</li>
<li><strong>重复迭代</strong>：上述过程重复进行多轮，直到达到预设的轮数或所有智能体的回答收敛。</li>
</ul>
<p>在此过程中，智能体被鼓励对其他智能体的回答进行批判性分析，并根据新的信息修正自己的观点。</p>
<h3 id="3-最终答案确定"><a href="#3-最终答案确定" class="headerlink" title="3. 最终答案确定"></a>3. 最终答案确定</h3><p>在多轮辩论后，系统通过多数投票或其他聚合方法，确定最终的答案。</p>
<p>该架构的关键在于利用多个智能体之间的互动，模拟人类的辩论过程，从而提升语言模型的表现。</p>
<h2 id="实验设置与结果"><a href="#实验设置与结果" class="headerlink" title="实验设置与结果"></a>实验设置与结果</h2><p>研究在多个任务上对MAD框架进行了评估，包括数学推理、传记事实验证和多项选择题等。实验结果显示，MAD框架在提升回答的准确性和推理质量方面表现优异，显著优于传统的单智能体方法。</p>
<p>此外，研究还发现，使用不同类型的语言模型作为智能体可以进一步提升性能，表明模型多样性对辩论过程有积极影响。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>MAD框架通过模拟人类的辩论机制，提供了一种有效提升语言模型事实性和推理能力的方法。该方法无需对模型进行微调，具有良好的通用性和可扩展性。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LLM/" rel="tag">LLM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/agent/" rel="tag">agent</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/multi-agent/" rel="tag">multi-agent</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/3/">Next &raquo;</a>
    </nav>
  
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2025 John Doe
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank" title="A fast, simple &amp; powerful blog framework">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="Another simple and elegant theme for Hexo  v3.5">Yelee</a> by MOxFIVE <i class="fa fa-heart animated infinite pulse"></i>
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" title="Site Visitors"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit"  title="Page Hits"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>
    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = 5;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>





<div class="scroll" id="scroll">
    <a href="#" title="Back to Top"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="Comments"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="Go to Bottom"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
            
            
            
            
            
            
             archives: ".archive-article-title", 
             miniArchives: "a.post-list-link", 
            
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>